#!/usr/bin/env python3
"""
Script pour tÃ©lÃ©charger et installer les ressources NLTK nÃ©cessaires
"""
import nltk
import ssl

def fix_nltk_downloads():
    """TÃ©lÃ©charge toutes les ressources NLTK nÃ©cessaires"""
    
    # Contournement SSL si nÃ©cessaire
    try:
        _create_unverified_https_context = ssl._create_unverified_context
    except AttributeError:
        pass
    else:
        ssl._create_default_https_context = _create_unverified_https_context
    
    print("ğŸ“¥ TÃ©lÃ©chargement des ressources NLTK...")
    
    # Liste des ressources nÃ©cessaires
    resources = [
        'punkt',           # Tokenizer classique
        'punkt_tab',       # Nouveau tokenizer
        'stopwords',       # Mots vides
        'wordnet',         # Base lexicale
        'omw-1.4',         # Multi-lingual wordnet
        'averaged_perceptron_tagger',  # POS tagger
    ]
    
    for resource in resources:
        try:
            print(f"  ğŸ“¦ TÃ©lÃ©chargement de {resource}...")
            nltk.download(resource, quiet=False)
            print(f"  âœ… {resource} installÃ© avec succÃ¨s")
        except Exception as e:
            print(f"  âŒ Erreur avec {resource}: {e}")
    
    print("\nğŸ‰ Installation des ressources NLTK terminÃ©e !")
    
    # Test de vÃ©rification
    print("\nğŸ§ª Test de vÃ©rification...")
    try:
        from nltk.tokenize import sent_tokenize, word_tokenize
        from nltk.corpus import stopwords
        
        test_text = "Ceci est un test. NLTK fonctionne correctement !"
        sentences = sent_tokenize(test_text)
        words = word_tokenize(test_text)
        
        print(f"  âœ… Segmentation en phrases : {len(sentences)} phrases")
        print(f"  âœ… Tokenisation : {len(words)} mots")
        print("  âœ… Tous les tests passent !")
        
    except Exception as e:
        print(f"  âŒ Erreur lors du test : {e}")

if __name__ == "__main__":
    fix_nltk_downloads()
