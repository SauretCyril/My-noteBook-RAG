"""Page de traitement par lots."""

import streamlit as st
import os
from typing import Dict, Any
from pathlib import Path

from ...services.batch_service import BatchService
from ...config.settings import VECTOR_DB_FILE
from ..components.debug_panel import show_debug_panel

def show() -> None:
    """Affiche la page de traitement par lots."""
    
    st.header("ğŸ“ Traitement par Lots")
    
    # VÃ©rification de la base vectorielle
    if 'vector_db' not in st.session_state:
        st.error("âš ï¸ Base vectorielle non initialisÃ©e")
        return
        
    vector_db = st.session_state.vector_db
    batch_service = BatchService(vector_db)
    
    # VÃ©rification et avertissement en cas de base obsolÃ¨te
    _check_and_warn_old_database()
    
    # Description des fonctionnalitÃ©s
    _show_features_description()
    
    # Interface principale
    _show_main_interface(batch_service)
    
    # Guide d'utilisation
    _show_usage_guide()

def _check_and_warn_database_conflicts(selected_sources=None):
    """VÃ©rifie les conflits entre la base vectorielle et les sources sÃ©lectionnÃ©es."""
    
    if 'vector_db' not in st.session_state:
        return
        
    vector_db = st.session_state.vector_db
    
    if not hasattr(vector_db, 'documents') or not vector_db.documents:
        st.info("ğŸ“Š **Base vectorielle vide** - PrÃªte pour l'indexation")
        return
    
    # Analyser les sources des documents existants
    actions_4b_count = 0
    actions_11_count = 0
    other_sources = {}
    total_docs = len(vector_db.documents)
    
    # Ã‰chantillonner les documents pour analyser les sources
    sample_size = min(100, total_docs)
    for doc in vector_db.documents[:sample_size]:
        source = doc.get('metadata', {}).get('source', '')
        if 'Actions-4b_new' in source:
            actions_4b_count += 1
        elif 'Actions-11-Projects' in source:
            actions_11_count += 1
        else:
            # Extraire le rÃ©pertoire racine pour les autres sources
            if source:
                # Chercher le rÃ©pertoire parent principal
                parts = source.replace('\\', '/').split('/')
                if len(parts) >= 3:
                    root_path = '/'.join(parts[:3])  # Ex: C:/Users/Documents
                    other_sources[root_path] = other_sources.get(root_path, 0) + 1
    
    # Extrapoler pour tous les documents
    ratio_4b = (actions_4b_count / sample_size) * total_docs if sample_size > 0 else 0
    ratio_11 = (actions_11_count / sample_size) * total_docs if sample_size > 0 else 0
    
    # Afficher l'Ã©tat de la base
    st.markdown("### ğŸ“Š Ã‰tat de la base vectorielle")
    
    # MÃ©triques principales
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ğŸ“„ Total documents", f"{total_docs:,}")
    with col2:
        st.metric("ğŸ“ Actions-4b_new", f"~{ratio_4b:.0f}")
    with col3:
        st.metric("ğŸ“ Actions-11-Projects", f"~{ratio_11:.0f}")
    
    # Afficher les autres sources si prÃ©sentes
    if other_sources:
        st.markdown("**ğŸ—‚ï¸ Autres sources dÃ©tectÃ©es :**")
        for source_path, count in sorted(other_sources.items(), key=lambda x: x[1], reverse=True)[:5]:
            estimated_total = (count / sample_size) * total_docs if sample_size > 0 else count
            st.write(f"ğŸ“ `{source_path}` : ~{estimated_total:.0f} documents")
    
    # Analyser les conflits avec les sources sÃ©lectionnÃ©es
    if selected_sources:
        # Si c'est une seule source (ancienne interface)
        if isinstance(selected_sources, str):
            selected_sources = [selected_sources]
        
        st.markdown("### âš ï¸ Analyse des conflits")
        
        conflicts_detected = False
        compatible_sources = []
        
        for source in selected_sources:
            if not os.path.exists(source):
                continue
                
            # VÃ©rifier la compatibilitÃ© avec la base existante
            is_actions_4b = "Actions-4b_new" in source
            is_actions_11 = "Actions-11-Projects" in source
            
            if is_actions_4b and ratio_11 > ratio_4b and ratio_11 > 10:
                st.warning(f"""
                âš ï¸ **Conflit dÃ©tectÃ© pour {os.path.basename(source)}**
                
                La base contient principalement des documents `Actions-11-Projects` 
                mais vous voulez traiter `Actions-4b_new`.
                """)
                conflicts_detected = True
                
            elif is_actions_11 and ratio_4b > ratio_11 and ratio_4b > 10:
                st.warning(f"""
                âš ï¸ **Conflit dÃ©tectÃ© pour {os.path.basename(source)}**
                
                La base contient principalement des documents `Actions-4b_new` 
                mais vous voulez traiter `Actions-11-Projects`.
                """)
                conflicts_detected = True
                
            elif is_actions_4b and ratio_4b > ratio_11:
                compatible_sources.append(source)
            elif is_actions_11 and ratio_11 > ratio_4b:
                compatible_sources.append(source)
            else:
                # Source personnalisÃ©e - vÃ©rifier si elle existe dÃ©jÃ 
                source_exists = False
                for existing_source in other_sources:
                    if source.replace('\\', '/').startswith(existing_source) or existing_source.startswith(source.replace('\\', '/')):
                        source_exists = True
                        compatible_sources.append(source)
                        break
                
                if not source_exists:
                    st.info(f"""
                    ğŸ’¡ **Nouvelle source dÃ©tectÃ©e : {os.path.basename(source)}**
                    
                    Cette source sera ajoutÃ©e Ã  la base existante.
                    """)
        
        # Afficher les sources compatibles
        if compatible_sources:
            st.success(f"""
            âœ… **Sources compatibles dÃ©tectÃ©es**
            
            {len(compatible_sources)} source(s) compatible(s) avec la base existante.
            Les nouveaux documents s'ajouteront aux existants.
            """)
        
        # Recommandations selon les conflits
        if conflicts_detected:
            st.markdown("""
            **ğŸ¯ Recommandations :**
            - ğŸ”„ **Ajouter** : Les nouveaux documents s'ajouteront aux existants (base mixte)
            - ğŸ§¹ **Nettoyer** : Vider la base avant traitement (recommandÃ© pour Ã©viter la confusion)
            """)
    
    # Boutons de gestion de la base
    st.markdown("### ğŸ§¹ Gestion de la base")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ§¹ Nettoyer la base", help="Vide complÃ¨tement la base vectorielle"):
            _clean_vector_database()
    
    with col2:
        if st.button("ğŸ“Š Analyser la base", help="Affiche les dÃ©tails de la base"):
            _show_database_analysis(vector_db)
    
    with col3:
        if st.button("ğŸ’¾ Sauvegarder", help="Force la sauvegarde de la base"):
            try:
                vector_db.save()
                st.success("âœ… Base sauvegardÃ©e")
            except Exception as e:
                st.error(f"âŒ Erreur sauvegarde: {e}")

def _show_database_analysis(vector_db):
    """Affiche une analyse dÃ©taillÃ©e de la base vectorielle."""
    
    st.markdown("#### ğŸ” Analyse dÃ©taillÃ©e")
    
    if not hasattr(vector_db, 'documents') or not vector_db.documents:
        st.info("Base vectorielle vide")
        return
    
    # Analyse des sources
    sources = {}
    for doc in vector_db.documents:
        source = doc.get('metadata', {}).get('source', 'Inconnu')
        # Extraire le rÃ©pertoire parent
        if 'Actions-4b_new' in source:
            repo = 'Actions-4b_new'
        elif 'Actions-11-Projects' in source:
            repo = 'Actions-11-Projects'
        else:
            repo = 'Autre'
        
        sources[repo] = sources.get(repo, 0) + 1
    
    # Afficher les statistiques
    for repo, count in sorted(sources.items()):
        percentage = (count / len(vector_db.documents)) * 100
        st.write(f"ğŸ“ **{repo}** : {count:,} documents ({percentage:.1f}%)")
    
    # Exemples de sources
    st.markdown("**Exemples de sources :**")
    sample_sources = set()
    for doc in vector_db.documents[:20]:
        source = doc.get('metadata', {}).get('source', '')
        if source:
            sample_sources.add(source)
    
    for source in list(sample_sources)[:5]:
        st.text(f"â€¢ {source}")
    
    if len(sample_sources) > 5:
        st.text(f"... et {len(sample_sources) - 5} autres")

def _check_and_warn_old_database():
    """VÃ©rifie si la base vectorielle contient des donnÃ©es de l'ancien rÃ©pertoire."""
    
    if 'vector_db' not in st.session_state:
        return
        
    vector_db = st.session_state.vector_db
    
    if not hasattr(vector_db, 'documents') or not vector_db.documents:
        return
    
    # VÃ©rifier les sources des documents
    old_path_count = 0
    new_path_count = 0
    total_docs = len(vector_db.documents)
    
    for doc in vector_db.documents[:50]:  # Ã‰chantillon des 50 premiers
        source = doc.get('metadata', {}).get('source', '')
        if 'Actions-4b_new' in source:
            old_path_count += 1
        elif 'Actions-11-Projects' in source:
            new_path_count += 1
    
    # Si la majoritÃ© des documents viennent de l'ancien rÃ©pertoire
    if old_path_count > new_path_count and old_path_count > 10:
        st.warning(f"""
        âš ï¸ **ATTENTION: Base vectorielle obsolÃ¨te dÃ©tectÃ©e**
        
        La base vectorielle contient {total_docs} documents de l'ancien rÃ©pertoire `Actions-4b_new`.
        
        **Recommandation:** Nettoyez la base avant de rÃ©indexer :
        1. Cliquez sur le bouton "ğŸ§¹ Nettoyer la base" ci-dessous
        2. Puis relancez le traitement par lots avec le bon rÃ©pertoire
        """)
        
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("ğŸ§¹ Nettoyer la base vectorielle", type="primary"):
                _clean_vector_database()

def _clean_vector_database():
    """Nettoie complÃ¨tement la base vectorielle."""
    try:
        # RÃ©initialiser la base vectorielle
        from ...core.vector_database import VectorDatabase
        
        # CrÃ©er une nouvelle base vide
        new_db = VectorDatabase()
        new_db.save()
        
        # Mettre Ã  jour la session
        st.session_state.vector_db = new_db
        
        st.success("âœ… Base vectorielle nettoyÃ©e avec succÃ¨s !")
        st.info("ğŸ”„ Vous pouvez maintenant lancer le traitement par lots")
        
        # Forcer le rechargement de la page
        st.rerun()
        
    except Exception as e:
        st.error(f"âŒ Erreur lors du nettoyage : {e}")

def _show_features_description() -> None:
    """Affiche la description des fonctionnalitÃ©s."""
    
    st.markdown("""
    ### ğŸ“‹ FonctionnalitÃ©s
    - **ğŸŒ Sources multiples** : Ajoutez n'importe quels rÃ©pertoires (locaux, rÃ©seau, cloud, USB)
    - **ğŸš€ Raccourcis rapides** : Boutons pour Actions-11-Projects, Actions-4b_new, Desktop, Documents
    - **âœï¸ Chemins personnalisÃ©s** : SpÃ©cifiez librement vos propres emplacements
    - **ğŸ” DÃ©tection intelligente** : Analyse automatique des conflits entre sources
    - **ğŸ“Š PrÃ©visualisation** : Scanner et analyser chaque source individuellement
    - **Parcours rÃ©cursif** : Traite tous les sous-dossiers automatiquement
    - **Fichiers d'annonce** : Utilise `._rag_.data`, `.data.json` et `"dossier"_notes.txt` pour contextualiser
    - **Mapping intelligent** : `description` â†’ nom projet, `dossier` â†’ numÃ©ro interne, `entreprise` â†’ sociÃ©tÃ© liÃ©e, `contact/tel/mail` â†’ informations de contact
    - **DÃ©tection CV/BA** : Identifie automatiquement les fichiers `*_CV_*.pdf` (candidatures) et `*_BA_*.pdf` (supports oraux)
    - **Niveau de maturitÃ©** : Calcule automatiquement le statut (ğŸ’¡ IdÃ©e â†’ ğŸš€ InitiÃ© â†’ ğŸ“¤ EnvoyÃ© â†’ ğŸ¤ DÃ©marche)
    - **MÃ©tadonnÃ©es enrichies** : Fusion automatique des diffÃ©rentes sources de mÃ©tadonnÃ©es
    - **Formats supportÃ©s** : PDF, TXT, PNG, JPG, JPEG
    - **Tags automatiques** : CatÃ©gories, projets, entreprises, contacts, notes personnalisÃ©es, prÃ©sentations
    - **ğŸ” Vision avancÃ©e** : OCR et classification d'images
    - **ğŸ’¾ Traitement parallÃ¨le** : Gestion simultanÃ©e de multiples sources avec agrÃ©gation des rÃ©sultats
    """)
    
    # Ajouter un lien vers le guide dÃ©taillÃ©
    st.info("""
    ğŸ“– **Nouveau !** Interface multi-sources flexible - Consultez le 
    [Guide Sources Multiples](GUIDE_SOURCES_MULTIPLES.md) pour tous les dÃ©tails.
    """)

def _show_main_interface(batch_service: BatchService) -> None:
    """Affiche l'interface principale de traitement."""
    
    st.markdown("### ğŸ“‚ Gestion des sources de donnÃ©es")
    
    # Initialiser la session pour les sources multiples
    if 'data_sources' not in st.session_state:
        st.session_state.data_sources = []
    
    # Section d'ajout de nouvelles sources
    with st.expander("â• Ajouter une nouvelle source", expanded=True):
        col1, col2 = st.columns([3, 1])
        
        with col1:
            # Raccourcis rapides
            st.markdown("**ğŸš€ Raccourcis rapides :**")
            quick_buttons = st.columns(4)
            
            with quick_buttons[0]:
                if st.button("ğŸ“ Actions-11-Projects", help="Projets actuels"):
                    new_source = "h:\\Entreprendre\\Actions-11-Projects"
                    if new_source not in st.session_state.data_sources:
                        st.session_state.data_sources.append(new_source)
                        st.rerun()
            
            with quick_buttons[1]:
                if st.button("ğŸ“ Actions-4b_new", help="Archives"):
                    new_source = "h:\\Entreprendre\\Actions-4b_new"
                    if new_source not in st.session_state.data_sources:
                        st.session_state.data_sources.append(new_source)
                        st.rerun()
            
            with quick_buttons[2]:
                if st.button("ğŸ“ Desktop", help="Bureau utilisateur"):
                    desktop = os.path.join(os.path.expanduser("~"), "Desktop")
                    if desktop not in st.session_state.data_sources:
                        st.session_state.data_sources.append(desktop)
                        st.rerun()
            
            with quick_buttons[3]:
                if st.button("ğŸ“ Documents", help="Dossier Documents"):
                    documents = os.path.join(os.path.expanduser("~"), "Documents")
                    if documents not in st.session_state.data_sources:
                        st.session_state.data_sources.append(documents)
                        st.rerun()
            
            st.markdown("**âœï¸ Ou spÃ©cifiez un chemin personnalisÃ© :**")
            
            # Saisie manuelle
            custom_path = st.text_input(
                "Chemin personnalisÃ©",
                placeholder="Ex: C:\\MesProjets\\Dossier1",
                help="Entrez le chemin complet vers votre rÃ©pertoire"
            )
            
        with col2:
            st.markdown("**Actions**")
            
            # Bouton d'ajout du chemin personnalisÃ©
            if st.button("â• Ajouter", disabled=not custom_path):
                if custom_path and os.path.exists(custom_path):
                    if custom_path not in st.session_state.data_sources:
                        st.session_state.data_sources.append(custom_path)
                        st.success(f"âœ… Source ajoutÃ©e")
                        st.rerun()
                    else:
                        st.warning("âš ï¸ Source dÃ©jÃ  prÃ©sente")
                elif custom_path:
                    st.error("âŒ Chemin introuvable")
            
            # Bouton de nettoyage
            if st.button("ğŸ—‘ï¸ Tout vider"):
                st.session_state.data_sources = []
                st.success("âœ… Sources vidÃ©es")
                st.rerun()
    
    # Affichage des sources configurÃ©es
    if st.session_state.data_sources:
        st.markdown("### ğŸ“‹ Sources configurÃ©es")
        
        # VÃ©rifier les conflits avec la base existante
        _check_and_warn_database_conflicts(st.session_state.data_sources)
        
        for i, source in enumerate(st.session_state.data_sources):
            col1, col2, col3, col4 = st.columns([3, 1.5, 1.5, 1])
            
            with col1:
                # IcÃ´ne selon le type de source
                if "Actions-11-Projects" in source:
                    icon = "ğŸ†•"
                    label = f"{icon} {os.path.basename(source)} (Projets actuels)"
                elif "Actions-4b_new" in source:
                    icon = "ğŸ“¦"
                    label = f"{icon} {os.path.basename(source)} (Archives)"
                else:
                    icon = "ğŸ“"
                    label = f"{icon} {os.path.basename(source)}"
                
                # VÃ©rifier l'existence
                if os.path.exists(source):
                    st.success(label)
                    # Compter les fichiers
                    try:
                        file_count = sum(len(files) for _, _, files in os.walk(source))
                        st.caption(f"ğŸ“Š ~{file_count:,} fichiers")
                    except:
                        st.caption("ğŸ“Š Analyse...")
                else:
                    st.error(f"âŒ {label} (introuvable)")
            
            with col2:
                # Bouton prÃ©visualisation avec texte
                if st.button("ğŸ‘ï¸ PrÃ©visualiser", key=f"preview_{i}", help="Scanner et analyser cette source"):
                    st.session_state[f'preview_source_{i}'] = True
                    st.rerun()
            
            with col3:
                # Bouton traitement individuel avec texte
                if st.button("ğŸš€ Traiter seul", key=f"process_{i}", help="Traiter cette source uniquement"):
                    # Options par dÃ©faut pour traitement individuel
                    default_options = {
                        'extensions': ['.pdf', '.txt', '.png', '.jpg', '.jpeg'],
                        'max_file_size': 100,
                        'enable_vision': False
                    }
                    _execute_single_source_processing(source, default_options, batch_service)
            
            with col4:
                # Bouton suppression
                if st.button("ğŸ—‘ï¸ Suppr.", key=f"delete_{i}", help="Supprimer cette source"):
                    st.session_state.data_sources.pop(i)
                    st.rerun()
        
        # Affichage des prÃ©visualisations
        for i, source in enumerate(st.session_state.data_sources):
            if st.session_state.get(f'preview_source_{i}', False):
                with st.expander(f"ğŸ‘ï¸ PrÃ©visualisation: {os.path.basename(source)}", expanded=True):
                    if st.button("âŒ Fermer", key=f"close_preview_{i}"):
                        st.session_state[f'preview_source_{i}'] = False
                        st.rerun()
                    
                    _show_source_preview(source, batch_service)
        
        # Interface de traitement global
        st.markdown("### ğŸš€ Traitement global")
        
        # Options de traitement
        options = _show_processing_options(batch_service)
        
        # Statistiques globales
        total_sources = len([s for s in st.session_state.data_sources if os.path.exists(s)])
        st.info(f"ğŸ“Š **{total_sources} source(s) valide(s)** configurÃ©e(s) pour le traitement")
        
        # Bouton de traitement global
        if st.button("â–¶ï¸ Traiter toutes les sources", type="primary", disabled=total_sources == 0):
            _execute_multi_source_processing(st.session_state.data_sources, options, batch_service)
    
    else:
        st.info("ğŸ“‚ **Aucune source configurÃ©e** - Ajoutez des rÃ©pertoires ci-dessus pour commencer")
        
        # Afficher l'Ã©tat de la base mÃªme sans sources
        _check_and_warn_database_conflicts()

def _show_processing_options(batch_service: BatchService) -> Dict[str, Any]:
    """Affiche les options de traitement."""
    
    st.markdown("### âš™ï¸ Options de Traitement")
    
    supported = batch_service.get_supported_extensions()
    
    extensions = st.multiselect(
        "Types de fichiers Ã  traiter",
        supported['all'],
        default=['.pdf', '.txt', '.png', '.jpg', '.jpeg'],
        help="SÃ©lectionnez les types de fichiers Ã  inclure dans le traitement"
    )
    
    max_file_size = st.slider(
        "Taille max par fichier (MB)",
        1, 200, 100,
        help="Fichiers plus volumineux seront ignorÃ©s"
    )
    
    # Option pour activer la vision avancÃ©e
    enable_vision = st.checkbox(
        "ğŸ” Activer la vision avancÃ©e pour les images",
        value=False,
        help="GÃ©nÃ¨re des descriptions automatiques et classifie les images (plus lent)"
    )
    
    if enable_vision:
        st.info("âš ï¸ Le traitement sera plus lent mais les images seront mieux analysÃ©es")
    
    return {
        'extensions': extensions,
        'max_file_size': max_file_size,
        'enable_vision': enable_vision
    }

def _show_source_preview(source_path: str, batch_service: BatchService) -> None:
    """Affiche la prÃ©visualisation d'une source spÃ©cifique."""
    
    if not os.path.exists(source_path):
        st.error("âŒ Source introuvable")
        return
    
    if st.button("ğŸ” Scanner cette source", key=f"scan_{source_path}"):
        with st.spinner(f"Scan de {source_path}..."):
            from ...utils.file_utils import find_files_recursive
            
            # Extensions par dÃ©faut
            extensions = ['.pdf', '.txt', '.png', '.jpg', '.jpeg']
            
            # Scan de la source
            files_found = find_files_recursive(source_path, extensions)
            
            if files_found:
                st.success(f"ğŸ“„ {len(files_found)} fichier(s) trouvÃ©(s)")
                
                # Statistiques par type
                file_types = {'pdf': 0, 'txt': 0, 'images': 0, 'other': 0}
                projects = set()
                categories = set()
                
                for file_path, metadata in files_found:
                    ext = os.path.splitext(file_path)[1].lower()
                    if ext == '.pdf':
                        file_types['pdf'] += 1
                    elif ext == '.txt':
                        file_types['txt'] += 1
                    elif ext in ['.png', '.jpg', '.jpeg']:
                        file_types['images'] += 1
                    else:
                        file_types['other'] += 1
                    
                    # Collecter projets et catÃ©gories
                    if metadata:
                        if metadata.get('project') and metadata['project'] != 'Projet par dÃ©faut':
                            projects.add(metadata['project'])
                        if metadata.get('category') and metadata['category'] != 'Non classÃ©':
                            categories.add(metadata['category'])
                
                # Affichage des stats de fichiers
                st.markdown("**ğŸ“Š Statistiques des fichiers :**")
                cols = st.columns(4)
                with cols[0]:
                    st.metric("ğŸ“„ PDF", file_types['pdf'])
                with cols[1]:
                    st.metric("ğŸ“ TXT", file_types['txt'])
                with cols[2]:
                    st.metric("ğŸ–¼ï¸ Images", file_types['images'])
                with cols[3]:
                    st.metric("ğŸ“ Autres", file_types['other'])
                
                # Affichage des projets dÃ©tectÃ©s
                if projects:
                    st.markdown("**ğŸ“‹ Projets dÃ©tectÃ©s :**")
                    st.info(f"ğŸ¯ **{len(projects)} projet(s)** identifiÃ©(s) depuis les fichiers .data.json")
                    for project in sorted(projects):
                        st.write(f"â€¢ ğŸ“‚ **{project}**")
                else:
                    st.warning("âš ï¸ Aucun projet spÃ©cifique dÃ©tectÃ© - utilisation du projet par dÃ©faut")
                
                # Affichage des catÃ©gories dÃ©tectÃ©es
                if categories:
                    st.markdown("**ğŸ·ï¸ CatÃ©gories dÃ©tectÃ©es :**")
                    st.info(f"ğŸ”– **{len(categories)} catÃ©gorie(s)** identifiÃ©e(s) depuis les fichiers .data.json")
                    for category in sorted(categories):
                        st.write(f"â€¢ ğŸ·ï¸ **{category}**")
                else:
                    st.warning("âš ï¸ Aucune catÃ©gorie spÃ©cifique dÃ©tectÃ©e - utilisation de 'Non classÃ©'")
                
                # Ã‰chantillon de fichiers avec mÃ©tadonnÃ©es dÃ©taillÃ©es
                st.markdown("**ğŸ“‹ Ã‰chantillon des fichiers avec mÃ©tadonnÃ©es :**")
                for i, (file_path, metadata) in enumerate(files_found[:5]):
                    with st.expander(f"ğŸ“„ {os.path.basename(file_path)}", expanded=False):
                        col1, col2 = st.columns(2)
                        with col1:
                            st.write(f"**ğŸ“ Chemin :** `{file_path}`")
                            if metadata.get('project'):
                                st.write(f"**ğŸ¯ Projet :** {metadata['project']}")
                            if metadata.get('category'):
                                st.write(f"**ğŸ·ï¸ CatÃ©gorie :** {metadata['category']}")
                        with col2:
                            if metadata.get('description'):
                                st.write(f"**ğŸ“ Description :** {metadata['description']}")
                            if metadata.get('author'):
                                st.write(f"**ğŸ‘¤ Auteur :** {metadata['author']}")
                            if metadata.get('date'):
                                st.write(f"**ğŸ“… Date :** {metadata['date']}")
                            if metadata.get('tags'):
                                st.write(f"**ğŸ·ï¸ Tags :** {metadata['tags']}")
                
                if len(files_found) > 5:
                    st.write(f"... et {len(files_found) - 5} autres fichiers")
                    
                # RÃ©sumÃ© des mÃ©tadonnÃ©es RAG
                st.markdown("**ğŸ¤– Analyse RAG :**")
                data_json_count = sum(1 for _, metadata in files_found if metadata.get('source_format') == 'data_json')
                if data_json_count > 0:
                    st.success(f"âœ… {data_json_count} fichier(s) .data.json trouvÃ©(s) et mappÃ©(s) vers le format RAG")
                    st.info("ğŸ“Š Chaque fichier .data.json reprÃ©sente un projet avec ses mÃ©tadonnÃ©es enrichies")
                else:
                    st.warning("âš ï¸ Aucun fichier .data.json trouvÃ© - mÃ©tadonnÃ©es limitÃ©es")
            else:
                st.warning("âš ï¸ Aucun fichier trouvÃ©")

def _execute_single_source_processing(source_path: str, options: Dict[str, Any], batch_service: BatchService) -> None:
    """ExÃ©cute le traitement sur une seule source avec progression dÃ©taillÃ©e."""
    
    from ...utils.file_utils import find_files_recursive
    
    # Scanner les fichiers d'abord
    with st.spinner("ğŸ” Scan des fichiers..."):
        files_found = find_files_recursive(source_path, options['extensions'])
    
    if not files_found:
        st.warning("âš ï¸ Aucun fichier trouvÃ© Ã  traiter")
        return
    
    total_files = len(files_found)
    st.success(f"ğŸ“Š **{total_files} fichier(s)** trouvÃ©(s) Ã  traiter")
    
    # Barres de progression
    progress_bar = st.progress(0)
    status_text = st.empty()
    file_counter = st.empty()
    
    # Fonction de callback pour mise Ã  jour
    def update_progress(current: int, total: int, current_file: str):
        progress = current / total if total > 0 else 0
        progress_bar.progress(progress)
        status_text.text(f"ğŸ“ {os.path.basename(current_file)}")
        file_counter.text(f"ğŸ“Š Progression : {current}/{total} fichiers traitÃ©s")
    
    # Traitement avec callback
    with st.spinner("ğŸ”„ Traitement en cours..."):
        results = batch_service.process_directory(
            directory=source_path,
            file_extensions=options['extensions'],
            progress_callback=update_progress,
            enable_vision=options['enable_vision']
        )
    
    # Finalisation
    progress_bar.progress(1.0)
    status_text.text("âœ… Traitement terminÃ© !")
    file_counter.text(f"ğŸ‰ **TerminÃ©** : {total_files}/{total_files} fichiers traitÃ©s")
    
    # Affichage des rÃ©sultats
    _show_processing_results(results, batch_service)

def _execute_multi_source_processing(sources: list, options: Dict[str, Any], batch_service: BatchService) -> None:
    """ExÃ©cute le traitement sur plusieurs sources."""
    
    # Filtrer les sources valides
    valid_sources = [s for s in sources if os.path.exists(s)]
    
    if not valid_sources:
        st.error("âŒ Aucune source valide Ã  traiter")
        return
    
    # Compter le nombre total de fichiers Ã  traiter
    st.info("ğŸ” Comptage des fichiers Ã  traiter...")
    total_files = 0
    files_by_source = {}
    
    for source in valid_sources:
        try:
            from ...utils.file_utils import find_files_recursive
            files_found = find_files_recursive(source, options['extensions'])
            files_by_source[source] = files_found
            total_files += len(files_found)
        except Exception as e:
            st.warning(f"âš ï¸ Erreur scan {os.path.basename(source)}: {e}")
            files_by_source[source] = []
    
    if total_files == 0:
        st.warning("âš ï¸ Aucun fichier Ã  traiter dans les sources sÃ©lectionnÃ©es")
        return
    
    st.success(f"ğŸ“Š **{total_files} fichier(s)** trouvÃ©(s) dans {len(valid_sources)} source(s)")
    
    # Barres de progression avec colonnes ajustÃ©es
    col1, col2 = st.columns([2, 1])
    
    with col1:
        progress_bar = st.progress(0)
        status_text = st.empty()
    
    with col2:
        file_counter = st.empty()
    
    total_results = {
        'success': 0,
        'errors': 0,
        'skipped': 0,
        'images_processed': [],
        'sources_processed': []
    }
    
    # Compteur global de fichiers traitÃ©s
    files_processed = 0
    
    # Fonction de callback pour mise Ã  jour de progression
    def update_global_progress(current_in_source: int, total_in_source: int, current_file: str):
        nonlocal files_processed
        files_processed += 1
        
        # Calculer le pourcentage global
        global_progress = files_processed / total_files if total_files > 0 else 0
        progress_bar.progress(min(global_progress, 1.0))
        
        # Afficher les informations dÃ©taillÃ©es avec texte plus court
        status_text.text(f"ï¿½ {os.path.basename(current_file)}")
        file_counter.metric("ğŸ“Š Progression", f"{files_processed}/{total_files}", delta=f"{int(global_progress*100)}%")
    
    # Traitement source par source
    for source_idx, source in enumerate(valid_sources):
        source_name = os.path.basename(source)
        files_in_source = files_by_source[source]
        
        if not files_in_source:
            st.info(f"â­ï¸ Source {source_name} : Aucun fichier Ã  traiter")
            continue
        
        st.info(f"ğŸ”„ **Source {source_idx + 1}/{len(valid_sources)}** : {source_name} ({len(files_in_source)} fichiers)")
        
        # Traitement de la source avec callback de progression
        try:
            results = batch_service.process_directory(
                directory=source,
                file_extensions=options['extensions'],
                progress_callback=update_global_progress,
                enable_vision=options['enable_vision']
            )
            
            # AgrÃ©ger les rÃ©sultats
            total_results['success'] += results.get('success', 0)
            total_results['errors'] += results.get('errors', 0)
            total_results['skipped'] += results.get('skipped', 0)
            total_results['images_processed'].extend(results.get('images_processed', []))
            
            total_results['sources_processed'].append({
                'source': source,
                'results': results
            })
            
            # Affichage des rÃ©sultats de la source
            source_success = results.get('success', 0)
            source_errors = results.get('errors', 0)
            if source_success > 0:
                st.success(f"âœ… {source_name} : {source_success} fichier(s) traitÃ©(s)")
            if source_errors > 0:
                st.error(f"âŒ {source_name} : {source_errors} erreur(s)")
            
        except Exception as e:
            st.error(f"âŒ Erreur traitement {source_name}: {e}")
            total_results['errors'] += len(files_in_source) if files_in_source else 1
    
    # Finalisation
    progress_bar.progress(1.0)
    status_text.text("âœ… Traitement terminÃ© !")
    file_counter.text(f"ğŸ‰ **TerminÃ©** : {files_processed}/{total_files} fichiers traitÃ©s")
    
    # Affichage des rÃ©sultats globaux
    _show_multi_source_results(total_results, batch_service)

def _show_processing_results(results: Dict[str, Any], batch_service: BatchService) -> None:
    """Affiche les rÃ©sultats du traitement d'une source unique."""
    
    # Statistiques gÃ©nÃ©rales
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("âœ… SuccÃ¨s", results.get('success', 0))
    with col2:
        st.metric("âŒ Erreurs", results.get('errors', 0))
    with col3:
        st.metric("â­ï¸ IgnorÃ©s", results.get('skipped', 0))
    with col4:
        st.metric("ğŸ–¼ï¸ Images", len(results.get('images_processed', [])))
    
    # Analyser les projets et catÃ©gories traitÃ©s
    _show_processed_projects_and_categories(batch_service)
    
    # Afficher les images traitÃ©es si disponibles
    if results.get('images_processed'):
        st.markdown("### ğŸ–¼ï¸ Images TraitÃ©es")
        for i, img_result in enumerate(results['images_processed'][:5]):
            with st.expander(f"ğŸ“¸ {os.path.basename(img_result['file'])}"):
                col1, col2 = st.columns([1, 2])
                
                with col1:
                    try:
                        from PIL import Image
                        image = Image.open(img_result['file'])
                        st.image(image, width=200)
                    except:
                        st.write("âŒ AperÃ§u non disponible")
                
                with col2:
                    st.write(f"**Description:** {img_result.get('description', 'N/A')}")
                    st.write(f"**CatÃ©gories:** {', '.join(img_result.get('categories', []))}")
                    if img_result.get('ocr_text'):
                        st.write(f"**Texte OCR:** {img_result['ocr_text']}")
        
        if len(results['images_processed']) > 5:
            st.write(f"... et {len(results['images_processed']) - 5} autres images")
    
    # Sauvegarder la base
    if results.get('success', 0) > 0:
        batch_service.vector_db.save()
        st.success(f"âœ… {results['success']} fichier(s) ajoutÃ©(s) Ã  la base !")
    
    # Afficher les erreurs
    if results.get('errors', 0) > 0:
        with st.expander("âŒ Voir les erreurs"):
            for error in results.get('errors_list', []):
                st.error(error)

def _show_multi_source_results(results: Dict[str, Any], batch_service: BatchService) -> None:
    """Affiche les rÃ©sultats du traitement multi-sources."""
    
    st.markdown("### ğŸ“Š RÃ©sultats du traitement")
    
    # Statistiques globales
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("âœ… SuccÃ¨s total", results['success'])
    with col2:
        st.metric("âŒ Erreurs", results['errors'])
    with col3:
        st.metric("â­ï¸ IgnorÃ©s", results['skipped'])
    with col4:
        st.metric("ğŸ–¼ï¸ Images", len(results['images_processed']))
    
    # Afficher les projets et catÃ©gories traitÃ©s
    _show_processed_projects_and_categories(batch_service)
    
    # DÃ©tails par source
    if results.get('sources_processed'):
        st.markdown("### ğŸ“ DÃ©tails par source")
        
        for source_data in results['sources_processed']:
            source = source_data['source']
            source_results = source_data['results']
            source_name = os.path.basename(source)
            
            with st.expander(f"ğŸ“‚ {source_name}"):
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("âœ… SuccÃ¨s", source_results.get('success', 0))
                with col2:
                    st.metric("âŒ Erreurs", source_results.get('errors', 0))
                with col3:
                    st.metric("â­ï¸ IgnorÃ©s", source_results.get('skipped', 0))
                
                # Afficher les erreurs de cette source si prÃ©sentes
                if source_results.get('errors_list'):
                    st.markdown("**âŒ Erreurs :**")
                    for error in source_results['errors_list'][:3]:
                        st.error(error)
                    if len(source_results['errors_list']) > 3:
                        st.write(f"... et {len(source_results['errors_list']) - 3} autres erreurs")
    
    # Images traitÃ©es globalement
    if results.get('images_processed'):
        st.markdown("### ğŸ–¼ï¸ Images traitÃ©es (toutes sources)")
        
        total_images = len(results['images_processed'])
        st.info(f"ğŸ“¸ {total_images} image(s) traitÃ©e(s) avec analyse automatique")
        
        # Ã‰chantillon d'images
        for i, img_result in enumerate(results['images_processed'][:3]):
            with st.expander(f"ğŸ“¸ {os.path.basename(img_result['file'])}"):
                col1, col2 = st.columns([1, 2])
                
                with col1:
                    try:
                        from PIL import Image
                        image = Image.open(img_result['file'])
                        st.image(image, width=150)
                    except:
                        st.write("âŒ AperÃ§u non disponible")
                
                with col2:
                    st.write(f"**Description:** {img_result.get('description', 'N/A')}")
                    st.write(f"**CatÃ©gories:** {', '.join(img_result.get('categories', []))}")
                    if img_result.get('ocr_text'):
                        st.write(f"**Texte OCR:** {img_result['ocr_text'][:100]}...")
        
        if total_images > 3:
            st.write(f"... et {total_images - 3} autres images")
    
    # Sauvegarder la base
    if results['success'] > 0:
        batch_service.vector_db.save()
        st.success(f"ğŸ‰ **{results['success']} fichier(s) au total** ajoutÃ©s Ã  la base RAG !")
        
        # Message de confirmation sur les projets
        st.info("""
        âœ… **Traitement terminÃ© avec succÃ¨s !**
        
        Les fichiers .data.json ont Ã©tÃ© automatiquement convertis en projets RAG.
        Utilisez la page "ğŸ’¬ Chat RAG" pour interroger vos donnÃ©es par projet ou catÃ©gorie.
        """)
    
    # RÃ©sumÃ© des erreurs
    if results['errors'] > 0:
        with st.expander(f"âŒ Voir toutes les erreurs ({results['errors']})"):
            all_errors = []
            for source_data in results.get('sources_processed', []):
                all_errors.extend(source_data['results'].get('errors_list', []))
            
            for error in all_errors:
                st.error(error)

def _show_processed_projects_and_categories(batch_service: BatchService) -> None:
    """Affiche les projets et catÃ©gories actuellement dans la base vectorielle."""
    
    if not hasattr(batch_service.vector_db, 'documents') or not batch_service.vector_db.documents:
        st.info("ğŸ“Š Base vectorielle vide")
        return
    
    # Analyser les documents dans la base
    projects = {}
    categories = {}
    data_json_projects = 0
    
    for doc in batch_service.vector_db.documents:
        metadata = doc.get('metadata', {})
        
        # Compter les projets .data.json
        if metadata.get('source_format') == 'data_json':
            data_json_projects += 1
        
        # Collecter projets
        project = metadata.get('project', 'Non spÃ©cifiÃ©')
        if project not in projects:
            projects[project] = {'count': 0, 'categories': set()}
        projects[project]['count'] += 1
        
        # Collecter catÃ©gories
        category = metadata.get('category', 'Non classÃ©')
        if category not in categories:
            categories[category] = 0
        categories[category] += 1
        projects[project]['categories'].add(category)
    
    # Affichage des projets
    st.markdown("### ğŸ¯ Projets dans la base RAG")
    
    if data_json_projects > 0:
        st.success(f"ğŸ“Š **{data_json_projects} projet(s)** issus de fichiers .data.json dÃ©tectÃ©s")
    
    if len(projects) > 1 or (len(projects) == 1 and 'Projet par dÃ©faut' not in projects):
        st.info(f"ğŸ“‚ **{len(projects)} projet(s)** identifiÃ©(s) au total")
        
        # Afficher les projets les plus importants
        sorted_projects = sorted(projects.items(), key=lambda x: x[1]['count'], reverse=True)
        
        for project, data in sorted_projects[:10]:  # Top 10
            categories_list = list(data['categories'])
            categories_str = ', '.join(categories_list[:3])
            if len(categories_list) > 3:
                categories_str += f" (+{len(categories_list)-3})"
            
            with st.expander(f"ğŸ“‚ **{project}** ({data['count']} documents)"):
                st.write(f"**ğŸ·ï¸ CatÃ©gories :** {categories_str}")
                st.write(f"**ğŸ“„ Documents :** {data['count']}")
        
        if len(sorted_projects) > 10:
            st.write(f"... et {len(sorted_projects) - 10} autres projets")
    else:
        st.warning("âš ï¸ Aucun projet spÃ©cifique dÃ©tectÃ© - tous les documents utilisent le projet par dÃ©faut")
    
    # Affichage des catÃ©gories
    st.markdown("### ğŸ·ï¸ CatÃ©gories dans la base RAG")
    
    if len(categories) > 1 or (len(categories) == 1 and 'Non classÃ©' not in categories):
        st.info(f"ğŸ”– **{len(categories)} catÃ©gorie(s)** identifiÃ©e(s)")
        
        # Afficher les catÃ©gories les plus frÃ©quentes
        sorted_categories = sorted(categories.items(), key=lambda x: x[1], reverse=True)
        
        cols = st.columns(min(3, len(sorted_categories)))
        for i, (category, count) in enumerate(sorted_categories[:6]):
            with cols[i % 3]:
                st.metric(f"ğŸ·ï¸ {category}", count)
        
        if len(sorted_categories) > 6:
            st.write(f"... et {len(sorted_categories) - 6} autres catÃ©gories")
    else:
        st.warning("âš ï¸ Aucune catÃ©gorie spÃ©cifique dÃ©tectÃ©e - tous les documents utilisent 'Non classÃ©'")
    
    # Information sur l'enrichissement automatique
    if data_json_projects > 0:
        st.markdown("### ğŸ¤– Enrichissement RAG automatique")
        st.info("""
        âœ… **Chaque fichier .data.json** est automatiquement traitÃ© comme un projet
        
        ğŸ”„ **Mapping automatique :**
        - `dossier` + `description` â†’ **Nom du projet**
        - `categorie` â†’ **CatÃ©gorie RAG**
        - `contact` / `entreprise` â†’ **Auteur**
        - `Date` â†’ **Date du projet**
        - Autres champs â†’ **Tags et mÃ©tadonnÃ©es enrichies**
        """)
    else:
        st.warning("""
        âš ï¸ **Aucun fichier .data.json dÃ©tectÃ©**
        
        Pour bÃ©nÃ©ficier de l'organisation par projets et catÃ©gories :
        - Ajoutez des fichiers `.data.json` dans vos sources
        - Chaque fichier reprÃ©sentera un projet avec ses mÃ©tadonnÃ©es
        """)

def _show_usage_guide() -> None:
    """Affiche le guide d'utilisation."""
    
    with st.expander("ğŸ“‹ Guide d'Utilisation"):
        st.markdown("""
        ### ğŸ“‚ Interface Multi-Sources
        
        Cette nouvelle interface vous permet d'ajouter **n'importe quelles sources** pour votre base RAG :
        
        #### â• **Ajout de Sources**
        - ğŸš€ **Raccourcis rapides** : Boutons pour Actions-11-Projects, Actions-4b_new, Desktop, Documents
        - âœï¸ **Chemin personnalisÃ©** : Saisissez n'importe quel rÃ©pertoire (local, rÃ©seau, cloud, USB)
        - âœ… **Validation automatique** : VÃ©rification d'existence et compatibilitÃ©
        
        #### ğŸ“‹ **Gestion des Sources**
        - ğŸ‘ï¸ **PrÃ©visualisation** : Scanner une source pour voir les fichiers
        - ğŸš€ **Traitement individuel** : Traiter une seule source avec progression dÃ©taillÃ©e
        - â–¶ï¸ **Traitement global** : Traiter toutes les sources en une fois
        - ğŸ—‘ï¸ **Suppression** : Retirer des sources de la liste
        
        #### ğŸ” **DÃ©tection Intelligente**
        - âš ï¸ **Analyse des conflits** : DÃ©tection automatique des incompatibilitÃ©s
        - ğŸ“Š **Recommandations** : Conseils pour gÃ©rer les sources mixtes
        - ğŸ§¹ **Nettoyage guidÃ©** : Suggestions de nettoyage de base
        
        #### ğŸ“Š **Progression DÃ©taillÃ©e**
        - ğŸ“ˆ **Comptage prÃ©alable** : Nombre total de fichiers Ã  traiter
        - ğŸ”„ **Progression temps rÃ©el** : Fichier actuel et pourcentage global
        - ğŸ“ **RÃ©sultats par source** : Statistiques dÃ©taillÃ©es par rÃ©pertoire
        
        ### ğŸ’¡ **Exemples d'Utilisation**
        
        **Projets multiples :**
        ```
        âœ… h:\\Entreprendre\\Actions-11-Projects (Actuels)
        âœ… h:\\Entreprendre\\Actions-4b_new (Archives)
        âœ… C:\\Users\\MonNom\\Desktop\\Brouillons
        ```
        
        **Ã‰quipe distribuÃ©e :**
        ```
        âœ… \\\\serveur\\projets\\equipe1
        âœ… \\\\serveur\\projets\\equipe2
        âœ… C:\\Users\\MonNom\\OneDrive\\Personnel
        ```
        
        ### âš™ï¸ **Options AvancÃ©es**
        - ğŸ“„ **Types de fichiers** : PDF, TXT, Images configurables
        - ğŸ“ **Taille maximale** : Limitation par fichier
        - ğŸ” **Vision avancÃ©e** : OCR et classification d'images
        - ğŸ’¾ **Sauvegarde automatique** : Base mise Ã  jour en continu
        
        ### ğŸ¯ **Conseils**
        - ğŸ” **PrÃ©visualisez** avant de traiter pour Ã©viter les erreurs
        - ğŸ§¹ **Nettoyez** la base en cas de conflits de sources
        - ğŸš€ **Traitez individuellement** pour tester une nouvelle source
        - â–¶ï¸ **Traitement global** pour l'efficacitÃ© maximale
        """)
    
    # Panneau de debug en bas de page
    show_debug_panel("batch_processing")
