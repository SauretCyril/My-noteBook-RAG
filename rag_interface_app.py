import streamlit as st
import json
import os
from datetime import datetime
import PyPDF2
import nltk
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.corpus import stopwords
import pickle
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re

# Configuration de la page
st.set_page_config(
    page_title="RAG Knowledge Base Manager",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Chemins des fichiers
DATA_DIR = "data"
KNOWLEDGE_BASE_FILE = os.path.join(DATA_DIR, "anthropic_docs.json")
BACKUP_FILE = os.path.join(DATA_DIR, "anthropic_docs.json.backup")
VECTOR_DB_FILE = os.path.join(DATA_DIR, "docs", "vector_db.pkl")

# Initialisation de NLTK
@st.cache_resource
def init_nltk():
    """Initialise les ressources NLTK n√©cessaires"""
    try:
        nltk.data.find('tokenizers/punkt')
        nltk.data.find('corpora/stopwords')
    except LookupError:
        nltk.download('punkt', quiet=True)
        nltk.download('stopwords', quiet=True)
    return True

# Classes pour la gestion vectorielle
class VectorDatabase:
    def __init__(self):
        self.documents = []
        self.vectors = None
        self.vectorizer = TfidfVectorizer(
            max_features=5000,
            stop_words='english',
            ngram_range=(1, 2)
        )
    
    def add_document(self, text, metadata):
        """Ajoute un document √† la base vectorielle"""
        self.documents.append({
            'text': text,
            'metadata': metadata,
            'timestamp': datetime.now().isoformat()
        })
        self._update_vectors()
    
    def _update_vectors(self):
        """Met √† jour les vecteurs TF-IDF"""
        if self.documents:
            texts = [doc['text'] for doc in self.documents]
            self.vectors = self.vectorizer.fit_transform(texts)
    
    def search(self, query, top_k=5):
        """Recherche les documents les plus similaires"""
        if not self.documents or self.vectors is None:
            return []
        
        query_vector = self.vectorizer.transform([query])
        similarities = cosine_similarity(query_vector, self.vectors)[0]
        
        # Obtenir les indices des documents les plus similaires
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        results = []
        for idx in top_indices:
            if similarities[idx] > 0:  # Seulement les r√©sultats pertinents
                results.append({
                    'document': self.documents[idx],
                    'similarity': similarities[idx]
                })
        
        return results
    
    def save(self, filepath):
        """Sauvegarde la base vectorielle"""
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        with open(filepath, 'wb') as f:
            pickle.dump(self, f)
    
    @classmethod
    def load(cls, filepath):
        """Charge la base vectorielle"""
        if os.path.exists(filepath):
            try:
                with open(filepath, 'rb') as f:
                    loaded_data = pickle.load(f)
                    # V√©rifier si c'est une instance de VectorDatabase
                    if isinstance(loaded_data, cls):
                        return loaded_data
                    else:
                        # Si c'est un autre format, cr√©er une nouvelle instance
                        st.warning("Format de base vectorielle incompatible. Cr√©ation d'une nouvelle base.")
                        return cls()
            except Exception as e:
                st.error(f"Erreur lors du chargement de la base vectorielle : {e}")
                return cls()
        return cls()

# Fonctions utilitaires
def create_backup(source_file):
    """Cr√©e une sauvegarde du fichier source"""
    if os.path.exists(source_file):
        with open(source_file, 'r', encoding='utf-8') as src:
            with open(BACKUP_FILE, 'w', encoding='utf-8') as dst:
                dst.write(src.read())
        return True
    return False

def load_knowledge_base():
    """Charge la base de connaissances JSON"""
    if os.path.exists(KNOWLEDGE_BASE_FILE):
        try:
            with open(KNOWLEDGE_BASE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            st.error(f"Erreur lors du chargement de la base : {e}")
            return {}
    return {}

def save_knowledge_base(data):
    """Sauvegarde la base de connaissances JSON"""
    try:
        # Cr√©er une sauvegarde
        create_backup(KNOWLEDGE_BASE_FILE)
        
        # Cr√©er le dossier si n√©cessaire
        os.makedirs(DATA_DIR, exist_ok=True)
        
        # Sauvegarder les nouvelles donn√©es
        with open(KNOWLEDGE_BASE_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        st.error(f"Erreur lors de la sauvegarde : {e}")
        return False

def extract_text_from_pdf(pdf_file):
    """Extrait le texte d'un fichier PDF"""
    try:
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        st.error(f"Erreur lors de l'extraction du PDF : {e}")
        return None

def segment_text(text, max_length=500):
    """Segmente le texte en chunks plus petits"""
    sentences = sent_tokenize(text)
    segments = []
    current_segment = ""
    
    for sentence in sentences:
        if len(current_segment) + len(sentence) <= max_length:
            current_segment += sentence + " "
        else:
            if current_segment:
                segments.append(current_segment.strip())
            current_segment = sentence + " "
    
    if current_segment:
        segments.append(current_segment.strip())
    
    return segments

def generate_response(query, context_docs):
    """G√©n√®re une r√©ponse bas√©e sur les documents trouv√©s"""
    if not context_docs:
        return "Je n'ai pas trouv√© d'informations pertinentes pour r√©pondre √† votre question."
    
    # Construire le contexte
    context = "\n\n".join([doc['document']['text'] for doc in context_docs])
    
    # Simulation d'une r√©ponse (√† remplacer par un vrai mod√®le)
    response = f"""Bas√© sur les documents de la base de connaissances, voici ma r√©ponse :

**Contexte trouv√© :**
{context[:800]}...

**R√©ponse :**
Je peux vous aider avec les informations trouv√©es dans les documents. Pour une r√©ponse plus pr√©cise, vous pouvez int√©grer un mod√®le de langage comme Mistral AI ou OpenAI.

**Sources utilis√©es :** {len(context_docs)} document(s) pertinent(s)"""
    
    return response

# Interface principale
def main():
    # Initialisation
    init_nltk()
    
    # Titre principal
    st.title("ü§ñ RAG Knowledge Base Manager")
    st.markdown("---")
    
    # Sidebar pour la navigation
    st.sidebar.title("üìã Menu Principal")
    page = st.sidebar.selectbox(
        "Choisissez une action :",
        ["üè† Accueil", "üóÉÔ∏è Gestion de la Base", "üìÑ Ajouter Documents", "‚ùì Poser Questions"]
    )
    
    # Chargement de la base vectorielle
    if 'vector_db' not in st.session_state:
        st.session_state.vector_db = VectorDatabase.load(VECTOR_DB_FILE)
    
    # Initialisation de l'historique des conversations
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    # Navigation entre les pages
    if page == "üè† Accueil":
        show_home_page()
    elif page == "üóÉÔ∏è Gestion de la Base":
        show_database_management()
    elif page == "üìÑ Ajouter Documents":
        show_document_upload()
    elif page == "‚ùì Poser Questions":
        show_question_interface()

def show_home_page():
    """Page d'accueil avec les statistiques"""
    st.header("üè† Tableau de Bord")
    
    # Statistiques de la base
    knowledge_base = load_knowledge_base()
    vector_db = st.session_state.vector_db
    
    # V√©rification de compatibilit√©
    if not isinstance(vector_db, VectorDatabase):
        st.warning("‚ö†Ô∏è Format de base vectorielle incompatible d√©tect√©. Recr√©ation automatique...")
        st.session_state.vector_db = VectorDatabase()
        vector_db = st.session_state.vector_db
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("üìö Documents JSON", len(knowledge_base))
    
    with col2:
        try:
            st.metric("üîç Documents Vectoris√©s", len(vector_db.documents))
        except AttributeError:
            st.metric("üîç Documents Vectoris√©s", 0)
    
    with col3:
        conversations = len(st.session_state.chat_history)
        st.metric("üí¨ Conversations", conversations)
    
    # Informations sur les fichiers
    st.markdown("### üìÅ √âtat des Fichiers")
    
    files_info = [
        ("Base JSON", KNOWLEDGE_BASE_FILE),
        ("Sauvegarde", BACKUP_FILE),
        ("Base Vectorielle", VECTOR_DB_FILE)
    ]
    
    for name, filepath in files_info:
        if os.path.exists(filepath):
            size = os.path.getsize(filepath) / 1024  # KB
            st.success(f"‚úÖ {name}: {size:.1f} KB")
        else:
            st.warning(f"‚ö†Ô∏è {name}: Non trouv√©")
    
    # Instructions rapides
    st.markdown("### üöÄ D√©marrage Rapide")
    st.markdown("""
    1. **Gestion de la Base** : Cr√©ez ou r√©initialisez votre base vectorielle
    2. **Ajouter Documents** : Uploadez des PDF pour enrichir votre base
    3. **Poser Questions** : Interrogez votre base de connaissances
    """)

def show_database_management():
    """Interface de gestion de la base vectorielle"""
    st.header("üóÉÔ∏è Gestion de la Base Vectorielle")
    
    vector_db = st.session_state.vector_db
    
    # V√©rification de compatibilit√©
    if not isinstance(vector_db, VectorDatabase):
        st.error("‚ö†Ô∏è Format de base vectorielle incompatible d√©tect√©. Cr√©ation d'une nouvelle base...")
        st.session_state.vector_db = VectorDatabase()
        vector_db = st.session_state.vector_db
    
    # Informations sur la base actuelle
    st.markdown("### üìä Statistiques Actuelles")
    col1, col2 = st.columns(2)
    
    with col1:
        try:
            st.info(f"üìÑ Documents stock√©s : {len(vector_db.documents)}")
        except AttributeError:
            st.error("Erreur de format de base. Recr√©ation en cours...")
            st.session_state.vector_db = VectorDatabase()
            vector_db = st.session_state.vector_db
            st.info(f"üìÑ Documents stock√©s : {len(vector_db.documents)}")
    
    with col2:
        if vector_db.vectors is not None:
            st.info(f"üî¢ Dimensions vectorielles : {vector_db.vectors.shape}")
        else:
            st.info("üî¢ Pas de vecteurs g√©n√©r√©s")
    
    # Actions de gestion
    st.markdown("### ‚öôÔ∏è Actions de Gestion")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üÜï Cr√©er Nouvelle Base", type="primary"):
            st.session_state.vector_db = VectorDatabase()
            st.success("‚úÖ Nouvelle base vectorielle cr√©√©e !")
            st.rerun()
    
    with col2:
        if st.button("üíæ Sauvegarder Base"):
            st.session_state.vector_db.save(VECTOR_DB_FILE)
            st.success("‚úÖ Base sauvegard√©e avec succ√®s !")
    
    with col3:
        if st.button("üîÑ Recharger Base"):
            st.session_state.vector_db = VectorDatabase.load(VECTOR_DB_FILE)
            st.success("‚úÖ Base recharg√©e !")
            st.rerun()
    
    # Affichage des documents
    if vector_db.documents:
        st.markdown("### üìö Documents dans la Base")
        for i, doc in enumerate(vector_db.documents):
            with st.expander(f"Document {i+1} - {doc['metadata'].get('title', 'Sans titre')}"):
                st.markdown(f"**Source:** {doc['metadata'].get('source', 'Inconnue')}")
                st.markdown(f"**Date:** {doc['timestamp']}")
                st.text_area("Contenu:", doc['text'][:500] + "..." if len(doc['text']) > 500 else doc['text'], height=100)

def show_document_upload():
    """Interface pour ajouter des documents"""
    st.header("üìÑ Ajouter des Documents")
    
    # Upload de fichiers
    uploaded_files = st.file_uploader(
        "Choisissez vos fichiers PDF",
        type=['pdf'],
        accept_multiple_files=True
    )
    
    if uploaded_files:
        for uploaded_file in uploaded_files:
            st.markdown(f"### üìé Traitement de : {uploaded_file.name}")
            
            # Extraction du texte
            with st.spinner("Extraction du texte..."):
                text = extract_text_from_pdf(uploaded_file)
            
            if text:
                st.success(f"‚úÖ Texte extrait : {len(text)} caract√®res")
                
                # Pr√©visualisation
                with st.expander("üëÄ Pr√©visualisation du texte"):
                    st.text_area("Contenu extrait:", text[:1000] + "..." if len(text) > 1000 else text, height=200)
                
                # Options de segmentation
                col1, col2 = st.columns(2)
                with col1:
                    max_segment_length = st.slider("Taille max des segments", 200, 1000, 500)
                with col2:
                    title = st.text_input("Titre du document", value=uploaded_file.name)
                
                # Bouton d'ajout
                if st.button(f"‚ûï Ajouter {uploaded_file.name} √† la base", key=f"add_{uploaded_file.name}"):
                    with st.spinner("Ajout en cours..."):
                        # V√©rification de la base vectorielle
                        vector_db = st.session_state.vector_db
                        if not isinstance(vector_db, VectorDatabase):
                            st.warning("‚ö†Ô∏è Recr√©ation de la base vectorielle...")
                            st.session_state.vector_db = VectorDatabase()
                            vector_db = st.session_state.vector_db
                        
                        # Segmentation
                        segments = segment_text(text, max_segment_length)
                        
                        # Ajout √† la base vectorielle
                        vector_db = st.session_state.vector_db
                        for i, segment in enumerate(segments):
                            metadata = {
                                'title': title,
                                'source': uploaded_file.name,
                                'segment': i + 1,
                                'total_segments': len(segments)
                            }
                            vector_db.add_document(segment, metadata)
                        
                        # Ajout √† la base JSON
                        knowledge_base = load_knowledge_base()
                        doc_id = f"doc_{len(knowledge_base) + 1}"
                        knowledge_base[doc_id] = {
                            'title': title,
                            'source': uploaded_file.name,
                            'content': text,
                            'segments': segments,
                            'timestamp': datetime.now().isoformat()
                        }
                        
                        # Sauvegarde
                        if save_knowledge_base(knowledge_base):
                            vector_db.save(VECTOR_DB_FILE)
                            st.success(f"‚úÖ Document ajout√© avec succ√®s ! ({len(segments)} segments cr√©√©s)")
                        else:
                            st.error("‚ùå Erreur lors de la sauvegarde")
            else:
                st.error("‚ùå Impossible d'extraire le texte du PDF")

def show_question_interface():
    """Interface pour poser des questions"""
    st.header("‚ùì Poser des Questions")
    
    vector_db = st.session_state.vector_db
    
    # V√©rification de compatibilit√©
    if not isinstance(vector_db, VectorDatabase):
        st.error("‚ö†Ô∏è Format de base vectorielle incompatible d√©tect√©. Cr√©ation d'une nouvelle base...")
        st.session_state.vector_db = VectorDatabase()
        vector_db = st.session_state.vector_db
    
    if not vector_db.documents:
        st.warning("‚ö†Ô∏è Aucun document dans la base. Ajoutez d'abord des documents.")
        return
    
    # Interface de chat
    st.markdown("### üí¨ Chat avec votre Base de Connaissances")
    
    # Affichage de l'historique
    for i, (question, answer) in enumerate(st.session_state.chat_history):
        st.markdown(f"**üë§ Question {i+1}:** {question}")
        st.markdown(f"**ü§ñ R√©ponse:** {answer}")
        st.markdown("---")
    
    # Nouvelle question
    question = st.text_input("üîç Posez votre question :", placeholder="Ex: Quelles sont les comp√©tences mentionn√©es dans les CV ?")
    
    col1, col2 = st.columns([1, 4])
    with col1:
        if st.button("üöÄ Rechercher", type="primary"):
            if question:
                with st.spinner("Recherche en cours..."):
                    # Recherche dans la base vectorielle
                    results = vector_db.search(question, top_k=5)
                    
                    if results:
                        # G√©n√©ration de la r√©ponse
                        response = generate_response(question, results)
                        
                        # Ajout √† l'historique
                        st.session_state.chat_history.append((question, response))
                        
                        # Affichage de la r√©ponse
                        st.markdown("### ü§ñ R√©ponse")
                        st.markdown(response)
                        
                        # Affichage des sources
                        st.markdown("### üìö Sources Utilis√©es")
                        for i, result in enumerate(results):
                            doc = result['document']
                            similarity = result['similarity']
                            with st.expander(f"Source {i+1} - Similarit√©: {similarity:.3f}"):
                                st.markdown(f"**Titre:** {doc['metadata'].get('title', 'Sans titre')}")
                                st.markdown(f"**Source:** {doc['metadata'].get('source', 'Inconnue')}")
                                st.text_area("Contenu:", doc['text'], height=100)
                    else:
                        st.warning("Aucun r√©sultat trouv√© pour votre question.")
    
    with col2:
        if st.button("üóëÔ∏è Effacer Historique"):
            st.session_state.chat_history = []
            st.success("Historique effac√© !")
            st.rerun()
    
    # Param√®tres de recherche
    with st.expander("‚öôÔ∏è Param√®tres de Recherche"):
        top_k = st.slider("Nombre de r√©sultats", 1, 10, 5)
        min_similarity = st.slider("Similarit√© minimale", 0.0, 1.0, 0.1)

if __name__ == "__main__":
    main()
