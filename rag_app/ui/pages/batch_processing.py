"""Page de traitement par lots."""

import streamlit as st
import os
from typing import Dict, Any
from pathlib import Path

from ...services.batch_service import BatchService
from ...config.settings import VECTOR_DB_FILE
from ..components.debug_panel import show_debug_panel

def show() -> None:
    """Affiche la page de traitement par lots."""
    
    st.header("üìÅ Traitement par Lots")
    
    # V√©rification de la base vectorielle
    if 'vector_db' not in st.session_state:
        st.error("‚ö†Ô∏è Base vectorielle non initialis√©e")
        return
        
    vector_db = st.session_state.vector_db
    batch_service = BatchService(vector_db)
    
    # V√©rification et avertissement en cas de base obsol√®te
    _check_and_warn_old_database()
    
    # Description des fonctionnalit√©s
    _show_features_description()
    
    # Interface principale
    _show_main_interface(batch_service)
    
    # Guide d'utilisation
    _show_usage_guide()

def _check_and_warn_database_conflicts(selected_sources=None):
    """V√©rifie les conflits entre la base vectorielle et les sources s√©lectionn√©es."""
    
    if 'vector_db' not in st.session_state:
        return
        
    vector_db = st.session_state.vector_db
    
    if not hasattr(vector_db, 'documents') or not vector_db.documents:
        st.info("üìä **Base vectorielle vide** - Pr√™te pour l'indexation")
        return
    
    # Analyser les sources des documents existants
    actions_4b_count = 0
    actions_11_count = 0
    other_sources = {}
    total_docs = len(vector_db.documents)
    
    # √âchantillonner les documents pour analyser les sources
    sample_size = min(100, total_docs)
    for doc in vector_db.documents[:sample_size]:
        source = doc.get('metadata', {}).get('source', '')
        if 'Actions-4b_new' in source:
            actions_4b_count += 1
        elif 'Actions-11-Projects' in source:
            actions_11_count += 1
        else:
            # Extraire le r√©pertoire racine pour les autres sources
            if source:
                # Chercher le r√©pertoire parent principal
                parts = source.replace('\\', '/').split('/')
                if len(parts) >= 3:
                    root_path = '/'.join(parts[:3])  # Ex: C:/Users/Documents
                    other_sources[root_path] = other_sources.get(root_path, 0) + 1
    
    # Extrapoler pour tous les documents
    ratio_4b = (actions_4b_count / sample_size) * total_docs if sample_size > 0 else 0
    ratio_11 = (actions_11_count / sample_size) * total_docs if sample_size > 0 else 0
    
    # Afficher l'√©tat de la base
    st.markdown("### üìä √âtat de la base vectorielle")
    
    # M√©triques principales
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("üìÑ Total documents", f"{total_docs:,}")
    with col2:
        st.metric("üìÅ Actions-4b_new", f"~{ratio_4b:.0f}")
    with col3:
        st.metric("üìÅ Actions-11-Projects", f"~{ratio_11:.0f}")
    
    # Afficher les autres sources si pr√©sentes
    if other_sources:
        st.markdown("**üóÇÔ∏è Autres sources d√©tect√©es :**")
        for source_path, count in sorted(other_sources.items(), key=lambda x: x[1], reverse=True)[:5]:
            estimated_total = (count / sample_size) * total_docs if sample_size > 0 else count
            st.write(f"üìÅ `{source_path}` : ~{estimated_total:.0f} documents")
    
    # Analyser les conflits avec les sources s√©lectionn√©es
    if selected_sources:
        # Si c'est une seule source (ancienne interface)
        if isinstance(selected_sources, str):
            selected_sources = [selected_sources]
        
        st.markdown("### ‚ö†Ô∏è Analyse des conflits")
        
        conflicts_detected = False
        compatible_sources = []
        
        for source in selected_sources:
            if not os.path.exists(source):
                continue
                
            # V√©rifier la compatibilit√© avec la base existante
            is_actions_4b = "Actions-4b_new" in source
            is_actions_11 = "Actions-11-Projects" in source
            
            if is_actions_4b and ratio_11 > ratio_4b and ratio_11 > 10:
                st.warning(f"""
                ‚ö†Ô∏è **Conflit d√©tect√© pour {os.path.basename(source)}**
                
                La base contient principalement des documents `Actions-11-Projects` 
                mais vous voulez traiter `Actions-4b_new`.
                """)
                conflicts_detected = True
                
            elif is_actions_11 and ratio_4b > ratio_11 and ratio_4b > 10:
                st.warning(f"""
                ‚ö†Ô∏è **Conflit d√©tect√© pour {os.path.basename(source)}**
                
                La base contient principalement des documents `Actions-4b_new` 
                mais vous voulez traiter `Actions-11-Projects`.
                """)
                conflicts_detected = True
                
            elif is_actions_4b and ratio_4b > ratio_11:
                compatible_sources.append(source)
            elif is_actions_11 and ratio_11 > ratio_4b:
                compatible_sources.append(source)
            else:
                # Source personnalis√©e - v√©rifier si elle existe d√©j√†
                source_exists = False
                for existing_source in other_sources:
                    if source.replace('\\', '/').startswith(existing_source) or existing_source.startswith(source.replace('\\', '/')):
                        source_exists = True
                        compatible_sources.append(source)
                        break
                
                if not source_exists:
                    st.info(f"""
                    üí° **Nouvelle source d√©tect√©e : {os.path.basename(source)}**
                    
                    Cette source sera ajout√©e √† la base existante.
                    """)
        
        # Afficher les sources compatibles
        if compatible_sources:
            st.success(f"""
            ‚úÖ **Sources compatibles d√©tect√©es**
            
            {len(compatible_sources)} source(s) compatible(s) avec la base existante.
            Les nouveaux documents s'ajouteront aux existants.
            """)
        
        # Recommandations selon les conflits
        if conflicts_detected:
            st.markdown("""
            **üéØ Recommandations :**
            - üîÑ **Ajouter** : Les nouveaux documents s'ajouteront aux existants (base mixte)
            - üßπ **Nettoyer** : Vider la base avant traitement (recommand√© pour √©viter la confusion)
            """)
    
    # Boutons de gestion de la base
    st.markdown("### üßπ Gestion de la base")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üßπ Nettoyer la base", help="Vide compl√®tement la base vectorielle"):
            _clean_vector_database()
    
    with col2:
        if st.button("üìä Analyser la base", help="Affiche les d√©tails de la base"):
            _show_database_analysis(vector_db)
    
    with col3:
        if st.button("üíæ Sauvegarder", help="Force la sauvegarde de la base"):
            try:
                vector_db.save()
                st.success("‚úÖ Base sauvegard√©e")
            except Exception as e:
                st.error(f"‚ùå Erreur sauvegarde: {e}")

def _show_database_analysis(vector_db):
    """Affiche une analyse d√©taill√©e de la base vectorielle."""
    
    st.markdown("#### üîç Analyse d√©taill√©e")
    
    if not hasattr(vector_db, 'documents') or not vector_db.documents:
        st.info("Base vectorielle vide")
        return
    
    # Analyse des sources
    sources = {}
    for doc in vector_db.documents:
        source = doc.get('metadata', {}).get('source', 'Inconnu')
        # Extraire le r√©pertoire parent
        if 'Actions-4b_new' in source:
            repo = 'Actions-4b_new'
        elif 'Actions-11-Projects' in source:
            repo = 'Actions-11-Projects'
        else:
            repo = 'Autre'
        
        sources[repo] = sources.get(repo, 0) + 1
    
    # Afficher les statistiques
    for repo, count in sorted(sources.items()):
        percentage = (count / len(vector_db.documents)) * 100
        st.write(f"üìÅ **{repo}** : {count:,} documents ({percentage:.1f}%)")
    
    # Exemples de sources
    st.markdown("**Exemples de sources :**")
    sample_sources = set()
    for doc in vector_db.documents[:20]:
        source = doc.get('metadata', {}).get('source', '')
        if source:
            sample_sources.add(source)
    
    for source in list(sample_sources)[:5]:
        st.text(f"‚Ä¢ {source}")
    
    if len(sample_sources) > 5:
        st.text(f"... et {len(sample_sources) - 5} autres")

def _check_and_warn_old_database():
    """V√©rifie si la base vectorielle contient des donn√©es de l'ancien r√©pertoire."""
    
    if 'vector_db' not in st.session_state:
        return
        
    vector_db = st.session_state.vector_db
    
    if not hasattr(vector_db, 'documents') or not vector_db.documents:
        return
    
    # V√©rifier les sources des documents
    old_path_count = 0
    new_path_count = 0
    total_docs = len(vector_db.documents)
    
    for doc in vector_db.documents[:50]:  # √âchantillon des 50 premiers
        source = doc.get('metadata', {}).get('source', '')
        if 'Actions-4b_new' in source:
            old_path_count += 1
        elif 'Actions-11-Projects' in source:
            new_path_count += 1
    
    # Si la majorit√© des documents viennent de l'ancien r√©pertoire
    if old_path_count > new_path_count and old_path_count > 10:
        st.warning(f"""
        ‚ö†Ô∏è **ATTENTION: Base vectorielle obsol√®te d√©tect√©e**
        
        La base vectorielle contient {total_docs} documents de l'ancien r√©pertoire `Actions-4b_new`.
        
        **Recommandation:** Nettoyez la base avant de r√©indexer :
        1. Cliquez sur le bouton "üßπ Nettoyer la base" ci-dessous
        2. Puis relancez le traitement par lots avec le bon r√©pertoire
        """)
        
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("üßπ Nettoyer la base vectorielle", type="primary"):
                _clean_vector_database()

def _clean_vector_database():
    """Nettoie compl√®tement la base vectorielle."""
    try:
        # R√©initialiser la base vectorielle
        from ...core.vector_database import VectorDatabase
        
        # Cr√©er une nouvelle base vide
        new_db = VectorDatabase()
        new_db.save()
        
        # Mettre √† jour la session
        st.session_state.vector_db = new_db
        
        st.success("‚úÖ Base vectorielle nettoy√©e avec succ√®s !")
        st.info("üîÑ Vous pouvez maintenant lancer le traitement par lots")
        
        # Forcer le rechargement de la page
        st.rerun()
        
    except Exception as e:
        st.error(f"‚ùå Erreur lors du nettoyage : {e}")

def _show_features_description() -> None:
    """Affiche la description des fonctionnalit√©s."""
    
    st.markdown("""
    ### üìã Fonctionnalit√©s
    - **üåê Sources multiples** : Ajoutez n'importe quels r√©pertoires (locaux, r√©seau, cloud, USB)
    - **üöÄ Raccourcis rapides** : Boutons pour Actions-11-Projects, Actions-4b_new, Desktop, Documents
    - **‚úèÔ∏è Chemins personnalis√©s** : Sp√©cifiez librement vos propres emplacements
    - **üîç D√©tection intelligente** : Analyse automatique des conflits entre sources
    - **üìä Pr√©visualisation** : Scanner et analyser chaque source individuellement
    - **Parcours r√©cursif** : Traite tous les sous-dossiers automatiquement
    - **Fichiers d'annonce** : Utilise `._rag_.data`, `.data.json` et `"dossier"_notes.txt` pour contextualiser
    - **Mapping intelligent** : `description` ‚Üí nom projet, `dossier` ‚Üí num√©ro interne, `entreprise` ‚Üí soci√©t√© li√©e, `contact/tel/mail` ‚Üí informations de contact
    - **D√©tection CV/BA** : Identifie automatiquement les fichiers `*_CV_*.pdf` (candidatures) et `*_BA_*.pdf` (supports oraux)
    - **Niveau de maturit√©** : Calcule automatiquement le statut (üí° Id√©e ‚Üí üöÄ Initi√© ‚Üí üì§ Envoy√© ‚Üí ü§ù D√©marche)
    - **M√©tadonn√©es enrichies** : Fusion automatique des diff√©rentes sources de m√©tadonn√©es
    - **Formats support√©s** : PDF, TXT, PNG, JPG, JPEG
    - **Tags automatiques** : Cat√©gories, projets, entreprises, contacts, notes personnalis√©es, pr√©sentations
    - **üîç Vision avanc√©e** : OCR et classification d'images
    - **üíæ Traitement parall√®le** : Gestion simultan√©e de multiples sources avec agr√©gation des r√©sultats
    """)
    
    # Ajouter un lien vers le guide d√©taill√©
    st.info("""
    üìñ **Nouveau !** Interface multi-sources flexible - Consultez le 
    [Guide Sources Multiples](GUIDE_SOURCES_MULTIPLES.md) pour tous les d√©tails.
    """)

def _show_main_interface(batch_service: BatchService) -> None:
    """Affiche l'interface principale de traitement."""
    
    st.markdown("### üìÇ Gestion des sources de donn√©es")
    
    # Initialiser la session pour les sources multiples
    if 'data_sources' not in st.session_state:
        st.session_state.data_sources = []
    
    # Section d'ajout de nouvelles sources
    with st.expander("‚ûï Ajouter une nouvelle source", expanded=True):
        col1, col2 = st.columns([3, 1])
        
        with col1:
            # Raccourcis rapides
            st.markdown("**üöÄ Raccourcis rapides :**")
            quick_buttons = st.columns(4)
            
            with quick_buttons[0]:
                if st.button("üìÅ Actions-11-Projects", help="Projets actuels"):
                    new_source = "h:\\Entreprendre\\Actions-11-Projects"
                    if new_source not in st.session_state.data_sources:
                        st.session_state.data_sources.append(new_source)
                        st.rerun()
            
            with quick_buttons[1]:
                if st.button("üìÅ Actions-4b_new", help="Archives"):
                    new_source = "h:\\Entreprendre\\Actions-4b_new"
                    if new_source not in st.session_state.data_sources:
                        st.session_state.data_sources.append(new_source)
                        st.rerun()
            
            with quick_buttons[2]:
                if st.button("üìÅ Desktop", help="Bureau utilisateur"):
                    desktop = os.path.join(os.path.expanduser("~"), "Desktop")
                    if desktop not in st.session_state.data_sources:
                        st.session_state.data_sources.append(desktop)
                        st.rerun()
            
            with quick_buttons[3]:
                if st.button("üìÅ Documents", help="Dossier Documents"):
                    documents = os.path.join(os.path.expanduser("~"), "Documents")
                    if documents not in st.session_state.data_sources:
                        st.session_state.data_sources.append(documents)
                        st.rerun()
            
            st.markdown("**‚úèÔ∏è Ou sp√©cifiez un chemin personnalis√© :**")
            
            # Saisie manuelle
            custom_path = st.text_input(
                "Chemin personnalis√©",
                placeholder="Ex: C:\\MesProjets\\Dossier1",
                help="Entrez le chemin complet vers votre r√©pertoire"
            )
            
        with col2:
            st.markdown("**Actions**")
            
            # Bouton d'ajout du chemin personnalis√©
            if st.button("‚ûï Ajouter", disabled=not custom_path):
                if custom_path and os.path.exists(custom_path):
                    if custom_path not in st.session_state.data_sources:
                        st.session_state.data_sources.append(custom_path)
                        st.success(f"‚úÖ Source ajout√©e")
                        st.rerun()
                    else:
                        st.warning("‚ö†Ô∏è Source d√©j√† pr√©sente")
                elif custom_path:
                    st.error("‚ùå Chemin introuvable")
            
            # Bouton de nettoyage
            if st.button("üóëÔ∏è Tout vider"):
                st.session_state.data_sources = []
                st.success("‚úÖ Sources vid√©es")
                st.rerun()
    
    # Affichage des sources configur√©es
    if st.session_state.data_sources:
        st.markdown("### üìã Sources configur√©es")
        
        # V√©rifier les conflits avec la base existante
        _check_and_warn_database_conflicts(st.session_state.data_sources)
        
        for i, source in enumerate(st.session_state.data_sources):
            col1, col2, col3, col4 = st.columns([3, 1.5, 1.5, 1])
            
            with col1:
                # Ic√¥ne selon le type de source
                if "Actions-11-Projects" in source:
                    icon = "üÜï"
                    label = f"{icon} {os.path.basename(source)} (Projets actuels)"
                elif "Actions-4b_new" in source:
                    icon = "üì¶"
                    label = f"{icon} {os.path.basename(source)} (Archives)"
                else:
                    icon = "üìÅ"
                    label = f"{icon} {os.path.basename(source)}"
                
                # V√©rifier l'existence
                if os.path.exists(source):
                    st.success(label)
                    # Compter les fichiers
                    try:
                        file_count = sum(len(files) for _, _, files in os.walk(source))
                        st.caption(f"üìä ~{file_count:,} fichiers")
                    except:
                        st.caption("üìä Analyse...")
                else:
                    st.error(f"‚ùå {label} (introuvable)")
            
            with col2:
                # Bouton pr√©visualisation avec texte
                if st.button("üëÅÔ∏è Pr√©visualiser", key=f"preview_{i}", help="Scanner et analyser cette source"):
                    st.session_state[f'preview_source_{i}'] = True
                    st.rerun()
            
            with col3:
                # Bouton traitement individuel avec texte
                if st.button("üöÄ Traiter seul", key=f"process_{i}", help="Traiter cette source uniquement"):
                    # Options par d√©faut pour traitement individuel
                    default_options = {
                        'extensions': ['.pdf', '.txt', '.png', '.jpg', '.jpeg'],
                        'max_file_size': 100,
                        'enable_vision': False
                    }
                    _execute_single_source_processing(source, default_options, batch_service)
            
            with col4:
                # Bouton suppression
                if st.button("üóëÔ∏è Suppr.", key=f"delete_{i}", help="Supprimer cette source"):
                    st.session_state.data_sources.pop(i)
                    st.rerun()
        
        # Affichage des pr√©visualisations
        for i, source in enumerate(st.session_state.data_sources):
            if st.session_state.get(f'preview_source_{i}', False):
                with st.expander(f"üëÅÔ∏è Pr√©visualisation: {os.path.basename(source)}", expanded=True):
                    if st.button("‚ùå Fermer", key=f"close_preview_{i}"):
                        st.session_state[f'preview_source_{i}'] = False
                        st.rerun()
                    
                    _show_source_preview(source, batch_service)
        
        # Interface de traitement global
        st.markdown("### üöÄ Traitement global")
        
        # Options de traitement
        options = _show_processing_options(batch_service)
        
        # Statistiques globales
        total_sources = len([s for s in st.session_state.data_sources if os.path.exists(s)])
        st.info(f"üìä **{total_sources} source(s) valide(s)** configur√©e(s) pour le traitement")
        
        # Bouton de traitement global
        if st.button("‚ñ∂Ô∏è Traiter toutes les sources", type="primary", disabled=total_sources == 0):
            _execute_multi_source_processing(st.session_state.data_sources, options, batch_service)
    
    else:
        st.info("üìÇ **Aucune source configur√©e** - Ajoutez des r√©pertoires ci-dessus pour commencer")
        
        # Afficher l'√©tat de la base m√™me sans sources
        _check_and_warn_database_conflicts()

def _show_processing_options(batch_service: BatchService) -> Dict[str, Any]:
    """Affiche les options de traitement."""
    
    st.markdown("### ‚öôÔ∏è Options de Traitement")
    
    supported = batch_service.get_supported_extensions()
    
    extensions = st.multiselect(
        "Types de fichiers √† traiter",
        supported['all'],
        default=['.pdf', '.txt', '.png', '.jpg', '.jpeg'],
        help="S√©lectionnez les types de fichiers √† inclure dans le traitement"
    )
    
    max_file_size = st.slider(
        "Taille max par fichier (MB)",
        1, 200, 100,
        help="Fichiers plus volumineux seront ignor√©s"
    )
    
    # Option pour activer la vision avanc√©e
    enable_vision = st.checkbox(
        "üîç Activer la vision avanc√©e pour les images",
        value=False,
        help="G√©n√®re des descriptions automatiques et classifie les images (plus lent)"
    )
    
    if enable_vision:
        st.info("‚ö†Ô∏è Le traitement sera plus lent mais les images seront mieux analys√©es")
    
    return {
        'extensions': extensions,
        'max_file_size': max_file_size,
        'enable_vision': enable_vision
    }

def _show_source_preview(source_path: str, batch_service: BatchService) -> None:
    """Affiche la pr√©visualisation d'une source sp√©cifique."""
    
    if not os.path.exists(source_path):
        st.error("‚ùå Source introuvable")
        return
    
    if st.button("üîç Scanner cette source", key=f"scan_{source_path}"):
        with st.spinner(f"Scan de {source_path}..."):
            from ...utils.file_utils import find_files_recursive
            
            # Extensions par d√©faut
            extensions = ['.pdf', '.txt', '.png', '.jpg', '.jpeg']
            
            # Scan de la source
            files_found = find_files_recursive(source_path, extensions)
            
            if files_found:
                st.success(f"üìÑ {len(files_found)} fichier(s) trouv√©(s)")
                
                # Statistiques par type
                file_types = {'pdf': 0, 'txt': 0, 'images': 0, 'other': 0}
                projects = set()
                categories = set()
                
                for file_path, metadata in files_found:
                    ext = os.path.splitext(file_path)[1].lower()
                    if ext == '.pdf':
                        file_types['pdf'] += 1
                    elif ext == '.txt':
                        file_types['txt'] += 1
                    elif ext in ['.png', '.jpg', '.jpeg']:
                        file_types['images'] += 1
                    else:
                        file_types['other'] += 1
                    
                    # Collecter projets et cat√©gories
                    if metadata:
                        if metadata.get('project') and metadata['project'] != 'Projet par d√©faut':
                            projects.add(metadata['project'])
                        if metadata.get('category') and metadata['category'] != 'Non class√©':
                            categories.add(metadata['category'])
                
                # Affichage des stats de fichiers
                st.markdown("**üìä Statistiques des fichiers :**")
                cols = st.columns(4)
                with cols[0]:
                    st.metric("üìÑ PDF", file_types['pdf'])
                with cols[1]:
                    st.metric("üìù TXT", file_types['txt'])
                with cols[2]:
                    st.metric("üñºÔ∏è Images", file_types['images'])
                with cols[3]:
                    st.metric("üìé Autres", file_types['other'])
                
                # Affichage des projets d√©tect√©s
                if projects:
                    st.markdown("**üìã Projets d√©tect√©s :**")
                    st.info(f"üéØ **{len(projects)} projet(s)** identifi√©(s) depuis les fichiers .data.json")
                    for project in sorted(projects):
                        st.write(f"‚Ä¢ üìÇ **{project}**")
                else:
                    st.warning("‚ö†Ô∏è Aucun projet sp√©cifique d√©tect√© - utilisation du projet par d√©faut")
                
                # Affichage des cat√©gories d√©tect√©es
                if categories:
                    st.markdown("**üè∑Ô∏è Cat√©gories d√©tect√©es :**")
                    st.info(f"üîñ **{len(categories)} cat√©gorie(s)** identifi√©e(s) depuis les fichiers .data.json")
                    for category in sorted(categories):
                        st.write(f"‚Ä¢ üè∑Ô∏è **{category}**")
                else:
                    st.warning("‚ö†Ô∏è Aucune cat√©gorie sp√©cifique d√©tect√©e - utilisation de 'Non class√©'")
                
                # √âchantillon de fichiers avec m√©tadonn√©es d√©taill√©es
                st.markdown("**üìã √âchantillon des fichiers avec m√©tadonn√©es :**")
                for i, (file_path, metadata) in enumerate(files_found[:5]):
                    with st.expander(f"üìÑ {os.path.basename(file_path)}", expanded=False):
                        col1, col2 = st.columns(2)
                        with col1:
                            st.write(f"**üìÅ Chemin :** `{file_path}`")
                            if metadata.get('project'):
                                st.write(f"**üéØ Projet :** {metadata['project']}")
                            if metadata.get('category'):
                                st.write(f"**üè∑Ô∏è Cat√©gorie :** {metadata['category']}")
                        with col2:
                            if metadata.get('description'):
                                st.write(f"**üìù Description :** {metadata['description']}")
                            if metadata.get('author'):
                                st.write(f"**üë§ Auteur :** {metadata['author']}")
                            if metadata.get('date'):
                                st.write(f"**üìÖ Date :** {metadata['date']}")
                            if metadata.get('tags'):
                                st.write(f"**üè∑Ô∏è Tags :** {metadata['tags']}")
                
                if len(files_found) > 5:
                    st.write(f"... et {len(files_found) - 5} autres fichiers")
                    
                # R√©sum√© des m√©tadonn√©es RAG
                st.markdown("**ü§ñ Analyse RAG :**")
                data_json_count = sum(1 for _, metadata in files_found if metadata.get('source_format') == 'data_json')
                if data_json_count > 0:
                    st.success(f"‚úÖ {data_json_count} fichier(s) .data.json trouv√©(s) et mapp√©(s) vers le format RAG")
                    st.info("üìä Chaque fichier .data.json repr√©sente un projet avec ses m√©tadonn√©es enrichies")
                else:
                    st.warning("‚ö†Ô∏è Aucun fichier .data.json trouv√© - m√©tadonn√©es limit√©es")
            else:
                st.warning("‚ö†Ô∏è Aucun fichier trouv√©")

def _execute_single_source_processing(source_path: str, options: Dict[str, Any], batch_service: BatchService) -> None:
    """Ex√©cute le traitement sur une seule source avec progression d√©taill√©e."""
    
    from ...utils.file_utils import find_files_recursive
    
    # Scanner les fichiers d'abord
    with st.spinner("üîç Scan des fichiers..."):
        files_found = find_files_recursive(source_path, options['extensions'])
    
    if not files_found:
        st.warning("‚ö†Ô∏è Aucun fichier trouv√© √† traiter")
        return
    
    total_files = len(files_found)
    st.success(f"üìä **{total_files} fichier(s)** trouv√©(s) √† traiter")
    
    # Barres de progression
    progress_bar = st.progress(0)
    status_text = st.empty()
    file_counter = st.empty()
    
    # Fonction de callback pour mise √† jour
    def update_progress(current: int, total: int, current_file: str):
        progress = current / total if total > 0 else 0
        progress_bar.progress(progress)
        status_text.text(f"üìÅ {os.path.basename(current_file)}")
        file_counter.text(f"üìä Progression : {current}/{total} fichiers trait√©s")
    
    # Traitement avec callback
    with st.spinner("üîÑ Traitement en cours..."):
        results = batch_service.process_directory(
            directory=source_path,
            file_extensions=options['extensions'],
            progress_callback=update_progress,
            enable_vision=options['enable_vision']
        )
    
    # Finalisation
    progress_bar.progress(1.0)
    status_text.text("‚úÖ Traitement termin√© !")
    file_counter.text(f"üéâ **Termin√©** : {total_files}/{total_files} fichiers trait√©s")
    
    # Affichage des r√©sultats
    _show_processing_results(results, batch_service)

def _execute_multi_source_processing(sources: list, options: Dict[str, Any], batch_service: BatchService) -> None:
    """Ex√©cute le traitement sur plusieurs sources."""
    
    # Filtrer les sources valides
    valid_sources = [s for s in sources if os.path.exists(s)]
    
    if not valid_sources:
        st.error("‚ùå Aucune source valide √† traiter")
        return
    
    # Compter le nombre total de fichiers √† traiter
    st.info("üîç Comptage des fichiers √† traiter...")
    total_files = 0
    files_by_source = {}
    
    for source in valid_sources:
        try:
            from ...utils.file_utils import find_files_recursive
            files_found = find_files_recursive(source, options['extensions'])
            files_by_source[source] = files_found
            total_files += len(files_found)
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Erreur scan {os.path.basename(source)}: {e}")
            files_by_source[source] = []
    
    if total_files == 0:
        st.warning("‚ö†Ô∏è Aucun fichier √† traiter dans les sources s√©lectionn√©es")
        return
    
    st.success(f"üìä **{total_files} fichier(s)** trouv√©(s) dans {len(valid_sources)} source(s)")
    
    # Barres de progression avec colonnes ajust√©es
    col1, col2 = st.columns([2, 1])
    
    with col1:
        progress_bar = st.progress(0)
        status_text = st.empty()
    
    with col2:
        file_counter = st.empty()
    
    total_results = {
        'success': 0,
        'errors': 0,
        'skipped': 0,
        'images_processed': [],
        'sources_processed': []
    }
    
    # Compteur global de fichiers trait√©s
    files_processed = 0
    
    # Fonction de callback pour mise √† jour de progression
    def update_global_progress(current_in_source: int, total_in_source: int, current_file: str):
        nonlocal files_processed
        files_processed += 1
        
        # Calculer le pourcentage global
        global_progress = files_processed / total_files if total_files > 0 else 0
        progress_bar.progress(min(global_progress, 1.0))
        
        # Afficher les informations d√©taill√©es avec texte plus court
        status_text.text(f"ÔøΩ {os.path.basename(current_file)}")
        file_counter.metric("üìä Progression", f"{files_processed}/{total_files}", delta=f"{int(global_progress*100)}%")
    
    # Traitement source par source
    for source_idx, source in enumerate(valid_sources):
        source_name = os.path.basename(source)
        files_in_source = files_by_source[source]
        
        if not files_in_source:
            st.info(f"‚è≠Ô∏è Source {source_name} : Aucun fichier √† traiter")
            continue
        
        st.info(f"üîÑ **Source {source_idx + 1}/{len(valid_sources)}** : {source_name} ({len(files_in_source)} fichiers)")
        
        # Traitement de la source avec callback de progression
        try:
            results = batch_service.process_directory(
                directory=source,
                file_extensions=options['extensions'],
                progress_callback=update_global_progress,
                enable_vision=options['enable_vision']
            )
            
            # Agr√©ger les r√©sultats
            total_results['success'] += results.get('success', 0)
            total_results['errors'] += results.get('errors', 0)
            total_results['skipped'] += results.get('skipped', 0)
            total_results['images_processed'].extend(results.get('images_processed', []))
            
            total_results['sources_processed'].append({
                'source': source,
                'results': results
            })
            
            # Affichage des r√©sultats de la source
            source_success = results.get('success', 0)
            source_errors = results.get('errors', 0)
            if source_success > 0:
                st.success(f"‚úÖ {source_name} : {source_success} fichier(s) trait√©(s)")
            if source_errors > 0:
                st.error(f"‚ùå {source_name} : {source_errors} erreur(s)")
            
        except Exception as e:
            st.error(f"‚ùå Erreur traitement {source_name}: {e}")
            total_results['errors'] += len(files_in_source) if files_in_source else 1
    
    # Finalisation
    progress_bar.progress(1.0)
    status_text.text("‚úÖ Traitement termin√© !")
    file_counter.text(f"üéâ **Termin√©** : {files_processed}/{total_files} fichiers trait√©s")
    
    # Affichage des r√©sultats globaux
    _show_multi_source_results(total_results, batch_service)

def _show_processing_results(results: Dict[str, Any], batch_service: BatchService) -> None:
    """Affiche les r√©sultats du traitement d'une source unique."""
    
    # Statistiques g√©n√©rales
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("‚úÖ Succ√®s", results.get('success', 0))
    with col2:
        st.metric("‚ùå Erreurs", results.get('errors', 0))
    with col3:
        st.metric("‚è≠Ô∏è Ignor√©s", results.get('skipped', 0))
    with col4:
        st.metric("üñºÔ∏è Images", len(results.get('images_processed', [])))
    
    # Analyser les projets et cat√©gories trait√©s
    _show_processed_projects_and_categories(batch_service)
    
    # Afficher les images trait√©es si disponibles
    if results.get('images_processed'):
        st.markdown("### üñºÔ∏è Images Trait√©es")
        for i, img_result in enumerate(results['images_processed'][:5]):
            with st.expander(f"üì∏ {os.path.basename(img_result['file'])}"):
                col1, col2 = st.columns([1, 2])
                
                with col1:
                    try:
                        from PIL import Image
                        image = Image.open(img_result['file'])
                        st.image(image, width=200)
                    except:
                        st.write("‚ùå Aper√ßu non disponible")
                
                with col2:
                    st.write(f"**Description:** {img_result.get('description', 'N/A')}")
                    st.write(f"**Cat√©gories:** {', '.join(img_result.get('categories', []))}")
                    if img_result.get('ocr_text'):
                        st.write(f"**Texte OCR:** {img_result['ocr_text']}")
        
        if len(results['images_processed']) > 5:
            st.write(f"... et {len(results['images_processed']) - 5} autres images")
    
    # Sauvegarder la base
    if results.get('success', 0) > 0:
        batch_service.vector_db.save()
        st.success(f"‚úÖ {results['success']} fichier(s) ajout√©(s) √† la base !")
    
    # Afficher les erreurs
    if results.get('errors', 0) > 0:
        with st.expander("‚ùå Voir les erreurs"):
            for error in results.get('errors_list', []):
                st.error(error)

def _show_multi_source_results(results: Dict[str, Any], batch_service: BatchService) -> None:
    """Affiche les r√©sultats du traitement multi-sources."""
    
    st.markdown("### üìä R√©sultats du traitement")
    
    # Statistiques globales
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("‚úÖ Succ√®s total", results['success'])
    with col2:
        st.metric("‚ùå Erreurs", results['errors'])
    with col3:
        st.metric("‚è≠Ô∏è Ignor√©s", results['skipped'])
    with col4:
        st.metric("üñºÔ∏è Images", len(results['images_processed']))
    
    # Afficher les projets et cat√©gories trait√©s
    _show_processed_projects_and_categories(batch_service)
    
    # D√©tails par source
    if results.get('sources_processed'):
        st.markdown("### üìÅ D√©tails par source")
        
        for source_data in results['sources_processed']:
            source = source_data['source']
            source_results = source_data['results']
            source_name = os.path.basename(source)
            
            with st.expander(f"üìÇ {source_name}"):
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("‚úÖ Succ√®s", source_results.get('success', 0))
                with col2:
                    st.metric("‚ùå Erreurs", source_results.get('errors', 0))
                with col3:
                    st.metric("‚è≠Ô∏è Ignor√©s", source_results.get('skipped', 0))
                
                # Afficher les erreurs de cette source si pr√©sentes
                if source_results.get('errors_list'):
                    st.markdown("**‚ùå Erreurs :**")
                    for error in source_results['errors_list'][:3]:
                        st.error(error)
                    if len(source_results['errors_list']) > 3:
                        st.write(f"... et {len(source_results['errors_list']) - 3} autres erreurs")
    
    # Images trait√©es globalement
    if results.get('images_processed'):
        st.markdown("### üñºÔ∏è Images trait√©es (toutes sources)")
        
        total_images = len(results['images_processed'])
        st.info(f"üì∏ {total_images} image(s) trait√©e(s) avec analyse automatique")
        
        # √âchantillon d'images
        for i, img_result in enumerate(results['images_processed'][:3]):
            with st.expander(f"üì∏ {os.path.basename(img_result['file'])}"):
                col1, col2 = st.columns([1, 2])
                
                with col1:
                    try:
                        from PIL import Image
                        image = Image.open(img_result['file'])
                        st.image(image, width=150)
                    except:
                        st.write("‚ùå Aper√ßu non disponible")
                
                with col2:
                    st.write(f"**Description:** {img_result.get('description', 'N/A')}")
                    st.write(f"**Cat√©gories:** {', '.join(img_result.get('categories', []))}")
                    if img_result.get('ocr_text'):
                        st.write(f"**Texte OCR:** {img_result['ocr_text'][:100]}...")
        
        if total_images > 3:
            st.write(f"... et {total_images - 3} autres images")
    
    # Sauvegarder la base
    if results['success'] > 0:
        batch_service.vector_db.save()
        st.success(f"üéâ **{results['success']} fichier(s) au total** ajout√©s √† la base RAG !")
        
        # Message de confirmation sur les projets
        st.info("""
        ‚úÖ **Traitement termin√© avec succ√®s !**
        
        Les fichiers .data.json ont √©t√© automatiquement convertis en projets RAG.
        Utilisez la page "üí¨ Chat RAG" pour interroger vos donn√©es par projet ou cat√©gorie.
        """)
    
    # R√©sum√© des erreurs
    if results['errors'] > 0:
        with st.expander(f"‚ùå Voir toutes les erreurs ({results['errors']})"):
            all_errors = []
            for source_data in results.get('sources_processed', []):
                all_errors.extend(source_data['results'].get('errors_list', []))
            
            for error in all_errors:
                st.error(error)

def _show_processed_projects_and_categories(batch_service: BatchService) -> None:
    """Affiche les projets et cat√©gories actuellement dans la base vectorielle."""
    
    if not hasattr(batch_service.vector_db, 'documents') or not batch_service.vector_db.documents:
        st.info("üìä Base vectorielle vide")
        return
    
    # Analyser les documents dans la base
    projects = {}
    categories = {}
    data_json_projects = 0
    
    for doc in batch_service.vector_db.documents:
        metadata = doc.get('metadata', {})
        
        # Compter les projets .data.json
        if metadata.get('source_format') == 'data_json':
            data_json_projects += 1
        
        # Collecter projets
        project = metadata.get('project', 'Non sp√©cifi√©')
        if project not in projects:
            projects[project] = {'count': 0, 'categories': set()}
        projects[project]['count'] += 1
        
        # Collecter cat√©gories
        category = metadata.get('category', 'Non class√©')
        if category not in categories:
            categories[category] = 0
        categories[category] += 1
        projects[project]['categories'].add(category)
    
    # Affichage des projets
    st.markdown("### üéØ Projets dans la base RAG")
    
    if data_json_projects > 0:
        st.success(f"üìä **{data_json_projects} projet(s)** issus de fichiers .data.json d√©tect√©s")
    
    if len(projects) > 1 or (len(projects) == 1 and 'Projet par d√©faut' not in projects):
        st.info(f"üìÇ **{len(projects)} projet(s)** identifi√©(s) au total")
        
        # Afficher les projets les plus importants
        sorted_projects = sorted(projects.items(), key=lambda x: x[1]['count'], reverse=True)
        
        for project, data in sorted_projects[:10]:  # Top 10
            categories_list = list(data['categories'])
            categories_str = ', '.join(categories_list[:3])
            if len(categories_list) > 3:
                categories_str += f" (+{len(categories_list)-3})"
            
            with st.expander(f"üìÇ **{project}** ({data['count']} documents)"):
                st.write(f"**üè∑Ô∏è Cat√©gories :** {categories_str}")
                st.write(f"**üìÑ Documents :** {data['count']}")
        
        if len(sorted_projects) > 10:
            st.write(f"... et {len(sorted_projects) - 10} autres projets")
    else:
        st.warning("‚ö†Ô∏è Aucun projet sp√©cifique d√©tect√© - tous les documents utilisent le projet par d√©faut")
    
    # Affichage des cat√©gories
    st.markdown("### üè∑Ô∏è Cat√©gories dans la base RAG")
    
    if len(categories) > 1 or (len(categories) == 1 and 'Non class√©' not in categories):
        st.info(f"üîñ **{len(categories)} cat√©gorie(s)** identifi√©e(s)")
        
        # Afficher les cat√©gories les plus fr√©quentes
        sorted_categories = sorted(categories.items(), key=lambda x: x[1], reverse=True)
        
        cols = st.columns(min(3, len(sorted_categories)))
        for i, (category, count) in enumerate(sorted_categories[:6]):
            with cols[i % 3]:
                st.metric(f"üè∑Ô∏è {category}", count)
        
        if len(sorted_categories) > 6:
            st.write(f"... et {len(sorted_categories) - 6} autres cat√©gories")
    else:
        st.warning("‚ö†Ô∏è Aucune cat√©gorie sp√©cifique d√©tect√©e - tous les documents utilisent 'Non class√©'")
    
    # Information sur l'enrichissement automatique
    if data_json_projects > 0:
        st.markdown("### ü§ñ Enrichissement RAG automatique")
        st.info("""
        ‚úÖ **Chaque fichier .data.json** est automatiquement trait√© comme un projet
        
        üîÑ **Mapping automatique :**
        - `dossier` + `description` ‚Üí **Nom du projet**
        - `categorie` ‚Üí **Cat√©gorie RAG**
        - `contact` / `entreprise` ‚Üí **Auteur**
        - `Date` ‚Üí **Date du projet**
        - Autres champs ‚Üí **Tags et m√©tadonn√©es enrichies**
        """)
    else:
        st.warning("""
        ‚ö†Ô∏è **Aucun fichier .data.json d√©tect√©**
        
        Pour b√©n√©ficier de l'organisation par projets et cat√©gories :
        - Ajoutez des fichiers `.data.json` dans vos sources
        - Chaque fichier repr√©sentera un projet avec ses m√©tadonn√©es
        """)

def _show_usage_guide() -> None:
    """Affiche le guide d'utilisation."""
    
    with st.expander("üìã Guide d'Utilisation"):
        st.markdown("""
        ### üìÇ Interface Multi-Sources
        
        Cette nouvelle interface vous permet d'ajouter **n'importe quelles sources** pour votre base RAG :
        
        #### ‚ûï **Ajout de Sources**
        - üöÄ **Raccourcis rapides** : Boutons pour Actions-11-Projects, Actions-4b_new, Desktop, Documents
        - ‚úèÔ∏è **Chemin personnalis√©** : Saisissez n'importe quel r√©pertoire (local, r√©seau, cloud, USB)
        - ‚úÖ **Validation automatique** : V√©rification d'existence et compatibilit√©
        
        #### üìã **Gestion des Sources**
        - üëÅÔ∏è **Pr√©visualisation** : Scanner une source pour voir les fichiers
        - üöÄ **Traitement individuel** : Traiter une seule source avec progression d√©taill√©e
        - ‚ñ∂Ô∏è **Traitement global** : Traiter toutes les sources en une fois
        - üóëÔ∏è **Suppression** : Retirer des sources de la liste
        
        #### üîç **D√©tection Intelligente**
        - ‚ö†Ô∏è **Analyse des conflits** : D√©tection automatique des incompatibilit√©s
        - üìä **Recommandations** : Conseils pour g√©rer les sources mixtes
        - üßπ **Nettoyage guid√©** : Suggestions de nettoyage de base
        
        #### üìä **Progression D√©taill√©e**
        - üìà **Comptage pr√©alable** : Nombre total de fichiers √† traiter
        - üîÑ **Progression temps r√©el** : Fichier actuel et pourcentage global
        - üìÅ **R√©sultats par source** : Statistiques d√©taill√©es par r√©pertoire
        
        ### üí° **Exemples d'Utilisation**
        
        **Projets multiples :**
        ```
        ‚úÖ h:\\Entreprendre\\Actions-11-Projects (Actuels)
        ‚úÖ h:\\Entreprendre\\Actions-4b_new (Archives)
        ‚úÖ C:\\Users\\MonNom\\Desktop\\Brouillons
        ```
        
        **√âquipe distribu√©e :**
        ```
        ‚úÖ \\\\serveur\\projets\\equipe1
        ‚úÖ \\\\serveur\\projets\\equipe2
        ‚úÖ C:\\Users\\MonNom\\OneDrive\\Personnel
        ```
        
        ### ‚öôÔ∏è **Options Avanc√©es**
        - üìÑ **Types de fichiers** : PDF, TXT, Images configurables
        - üìè **Taille maximale** : Limitation par fichier
        - üîç **Vision avanc√©e** : OCR et classification d'images
        - üíæ **Sauvegarde automatique** : Base mise √† jour en continu
        
        ### üéØ **Conseils**
        - üîç **Pr√©visualisez** avant de traiter pour √©viter les erreurs
        - üßπ **Nettoyez** la base en cas de conflits de sources
        - üöÄ **Traitez individuellement** pour tester une nouvelle source
        - ‚ñ∂Ô∏è **Traitement global** pour l'efficacit√© maximale
        """)
    
    # Panneau de debug en bas de page
    show_debug_panel("batch_processing")
